2025-02-24 19:06:07,878 - lightrag - INFO - Logger initialized for working directory: ./examples
2025-02-24 19:06:07,879 - lightrag - INFO - Load KV llm_response_cache with 0 data
2025-02-24 19:06:07,880 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-24 19:06:07,880 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-24 19:06:07,881 - lightrag - INFO - Loaded document status storage with 0 records
2025-02-24 19:06:48,546 - lightrag - INFO - Logger initialized for working directory: ./examples
2025-02-24 19:06:48,546 - lightrag - INFO - Load KV llm_response_cache with 0 data
2025-02-24 19:06:48,547 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-24 19:06:48,547 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-24 19:06:48,548 - lightrag - INFO - Loaded document status storage with 0 records
2025-02-24 19:06:48,548 - lightrag - INFO - Processing 1 new unique documents
2025-02-24 19:06:48,910 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-24 19:06:50,623 - lightrag - ERROR - Failed to process document doc-93fb037a9b290f5da4e87566e3756b68: object Tensor can't be used in 'await' expression
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 487, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 443, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
TypeError: object Tensor can't be used in 'await' expression

2025-02-24 19:06:50,624 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-24 19:07:35,952 - lightrag - INFO - Logger initialized for working directory: ./examples
2025-02-24 19:07:35,953 - lightrag - INFO - Load KV llm_response_cache with 0 data
2025-02-24 19:07:35,953 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-24 19:07:35,954 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-24 19:07:35,955 - lightrag - INFO - Loaded graph from ./examples/graph_chunk_entity_relation.graphml with 0 nodes, 0 edges
2025-02-24 19:07:35,956 - lightrag - INFO - Loaded document status storage with 1 records
2025-02-24 19:07:35,956 - lightrag - INFO - Processing 1 new unique documents
2025-02-24 19:07:36,229 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-24 19:07:37,580 - lightrag - ERROR - Failed to process document doc-93fb037a9b290f5da4e87566e3756b68: object Tensor can't be used in 'await' expression
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 487, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 443, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
TypeError: object Tensor can't be used in 'await' expression

2025-02-24 19:07:37,581 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-24 19:07:39,981 - lightrag - INFO - kw_prompt result:
2025-02-24 19:35:16,109 - lightrag - INFO - Logger initialized for working directory: ./examples
2025-02-24 19:35:16,110 - lightrag - INFO - Load KV llm_response_cache with 0 data
2025-02-24 19:35:16,110 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-24 19:35:16,110 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-24 19:35:16,111 - lightrag - INFO - Loaded graph from ./examples/graph_chunk_entity_relation.graphml with 0 nodes, 0 edges
2025-02-24 19:35:16,113 - lightrag - INFO - Loaded document status storage with 1 records
2025-02-24 19:35:16,113 - lightrag - INFO - Processing 1 new unique documents
2025-02-24 19:35:16,445 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-24 19:35:17,971 - lightrag - ERROR - Failed to process document doc-93fb037a9b290f5da4e87566e3756b68: can't convert cuda:3 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 487, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 443, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 148, in upsert
    embeddings = np.concatenate(embeddings_list)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/_tensor.py", line 1062, in __array__
    return self.numpy()
TypeError: can't convert cuda:3 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.

2025-02-24 19:35:17,972 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-24 19:35:20,201 - lightrag - INFO - kw_prompt result:
2025-02-24 19:40:29,965 - lightrag - INFO - Logger initialized for working directory: ./examples
2025-02-24 19:40:29,966 - lightrag - INFO - Load KV llm_response_cache with 0 data
2025-02-24 19:40:29,966 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-24 19:40:29,966 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-24 19:40:29,968 - lightrag - INFO - Loaded graph from ./examples/graph_chunk_entity_relation.graphml with 0 nodes, 0 edges
2025-02-24 19:40:29,969 - lightrag - INFO - Loaded document status storage with 1 records
2025-02-24 19:40:29,970 - lightrag - INFO - Processing 1 new unique documents
2025-02-24 19:40:30,263 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-24 19:41:47,468 - lightrag - INFO - Inserting entities into storage...
2025-02-24 19:41:47,473 - lightrag - INFO - Inserting relationships into storage...
2025-02-24 19:41:47,475 - lightrag - INFO - Inserting 23 vectors to entities
2025-02-24 19:41:48,399 - lightrag - INFO - Inserting 17 vectors to relationships
2025-02-24 19:41:49,164 - lightrag - INFO - Writing graph with 23 nodes, 17 edges
2025-02-24 19:41:50,961 - lightrag - INFO - kw_prompt result:
2025-02-24 19:41:51,086 - lightrag - INFO - Global query uses 18 entites, 17 relations, 1 text units
2025-02-26 10:58:50,268 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 10:58:50,268 - lightrag - INFO - Load KV llm_response_cache with 0 data
2025-02-26 10:58:50,268 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-26 10:58:50,268 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-26 10:58:50,269 - lightrag - INFO - Loaded document status storage with 0 records
2025-02-26 11:02:39,752 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 11:02:39,752 - lightrag - INFO - Load KV llm_response_cache with 0 data
2025-02-26 11:02:39,752 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-26 11:02:39,752 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-26 11:02:39,753 - lightrag - INFO - Loaded document status storage with 0 records
2025-02-26 11:02:39,753 - lightrag - INFO - Processing 16 new unique documents
2025-02-26 11:02:40,047 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:02:40,551 - lightrag - ERROR - Failed to process document doc-8015917e642f192276962dc5c82f0035: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:02:40,552 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:02:40,554 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:02:40,594 - lightrag - ERROR - Failed to process document doc-87881fb36e9f5389c75454c7761ece0b: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:02:40,594 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:02:40,596 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:02:40,627 - lightrag - ERROR - Failed to process document doc-e71b8ae320acf14bee521dfdab980576: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:02:40,627 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:02:40,635 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:02:40,666 - lightrag - ERROR - Failed to process document doc-d12f739158f5b66cda3554b96920d8a4: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:02:40,667 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:02:40,671 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:02:40,702 - lightrag - ERROR - Failed to process document doc-195a24eb60b89466c3ddafe26e48cfc2: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:02:40,703 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:02:40,722 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:02:40,753 - lightrag - ERROR - Failed to process document doc-f01954951a58e51263cca96d62fefb00: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:02:40,754 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:02:40,755 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:02:40,787 - lightrag - ERROR - Failed to process document doc-97d5d4a638969d5050c48d064dcbf3cc: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:02:40,788 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:02:40,789 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:02:40,820 - lightrag - ERROR - Failed to process document doc-8f1f49d7eec9c94cedbca85b3bd8ad8d: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:02:40,821 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:02:40,822 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:02:40,853 - lightrag - ERROR - Failed to process document doc-f03ca51227f347be6fdcad636c12c88b: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:02:40,854 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:02:40,854 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:02:40,886 - lightrag - ERROR - Failed to process document doc-4b5552c7ac55663b2b002dd63cf226b4: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:02:40,887 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:02:40,888 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:02:40,922 - lightrag - ERROR - Failed to process document doc-40a9c7823f84619ed461ccd4f6a33e1b: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:02:40,923 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:02:40,951 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:02:40,983 - lightrag - ERROR - Failed to process document doc-f5c5fd1419b86cc720719afc69a5f08e: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:02:40,984 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:02:40,985 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:02:41,020 - lightrag - ERROR - Failed to process document doc-a4e3ed87c1b2beb7081af8f6bbfb2389: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:02:41,020 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:02:41,021 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:02:41,053 - lightrag - ERROR - Failed to process document doc-c820138584e3628b850829a18b54dc68: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:02:41,053 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:02:41,056 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:02:41,088 - lightrag - ERROR - Failed to process document doc-1f8756f59446a38107a8be1aa9b6a8fd: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:02:41,088 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:02:41,089 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:02:41,125 - lightrag - ERROR - Failed to process document doc-458c5ff459d71ac15159de1660037e10: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:02:41,125 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:04:16,867 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 11:04:16,867 - lightrag - INFO - Load KV llm_response_cache with 0 data
2025-02-26 11:04:16,867 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-26 11:04:16,867 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-26 11:04:16,868 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 0 nodes, 0 edges
2025-02-26 11:04:16,869 - lightrag - INFO - Loaded document status storage with 16 records
2025-02-26 11:04:16,869 - lightrag - INFO - Processing 16 new unique documents
2025-02-26 11:04:17,149 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:04:17,684 - lightrag - ERROR - Failed to process document doc-e71b8ae320acf14bee521dfdab980576: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:04:17,685 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:04:17,687 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:04:17,726 - lightrag - ERROR - Failed to process document doc-a4e3ed87c1b2beb7081af8f6bbfb2389: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:04:17,727 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:04:17,755 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:04:17,794 - lightrag - ERROR - Failed to process document doc-87881fb36e9f5389c75454c7761ece0b: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:04:17,795 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:04:17,797 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:04:17,828 - lightrag - ERROR - Failed to process document doc-8015917e642f192276962dc5c82f0035: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:04:17,829 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:04:17,830 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:04:17,865 - lightrag - ERROR - Failed to process document doc-40a9c7823f84619ed461ccd4f6a33e1b: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:04:17,866 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:04:17,892 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:04:17,927 - lightrag - ERROR - Failed to process document doc-458c5ff459d71ac15159de1660037e10: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:04:17,928 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:04:17,929 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:04:17,961 - lightrag - ERROR - Failed to process document doc-8f1f49d7eec9c94cedbca85b3bd8ad8d: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:04:17,961 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:04:17,962 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:04:17,995 - lightrag - ERROR - Failed to process document doc-97d5d4a638969d5050c48d064dcbf3cc: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:04:17,995 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:04:17,996 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:04:18,028 - lightrag - ERROR - Failed to process document doc-1f8756f59446a38107a8be1aa9b6a8fd: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:04:18,029 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:04:18,030 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:04:18,061 - lightrag - ERROR - Failed to process document doc-195a24eb60b89466c3ddafe26e48cfc2: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:04:18,062 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:04:18,063 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:04:18,095 - lightrag - ERROR - Failed to process document doc-4b5552c7ac55663b2b002dd63cf226b4: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:04:18,096 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:04:18,097 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:04:18,128 - lightrag - ERROR - Failed to process document doc-c820138584e3628b850829a18b54dc68: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:04:18,129 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:04:18,161 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:04:18,193 - lightrag - ERROR - Failed to process document doc-f01954951a58e51263cca96d62fefb00: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:04:18,193 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:04:18,195 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:04:18,226 - lightrag - ERROR - Failed to process document doc-f03ca51227f347be6fdcad636c12c88b: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:04:18,227 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:04:18,228 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:04:18,259 - lightrag - ERROR - Failed to process document doc-d12f739158f5b66cda3554b96920d8a4: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:04:18,260 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:04:18,290 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:04:18,321 - lightrag - ERROR - Failed to process document doc-f5c5fd1419b86cc720719afc69a5f08e: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 610, in ainsert
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 221, in forward
    outputs = self.language_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 147, in forward
    layer_outputs = decoder_layer(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 716, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py", line 93, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:4!

2025-02-26 11:04:18,322 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:09:07,543 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 11:09:07,544 - lightrag - INFO - Load KV llm_response_cache with 0 data
2025-02-26 11:09:07,544 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-26 11:09:07,544 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-26 11:09:07,545 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 0 nodes, 0 edges
2025-02-26 11:09:07,546 - lightrag - INFO - Loaded document status storage with 16 records
2025-02-26 11:09:07,546 - lightrag - INFO - Processing 16 new unique documents
2025-02-26 11:09:07,824 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:09:09,211 - lightrag - ERROR - Failed to process document doc-195a24eb60b89466c3ddafe26e48cfc2: extract_entities() missing 2 required positional arguments: 'img' and 'content'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 613, in ainsert
    maybe_new_kg = await extract_entities(
TypeError: extract_entities() missing 2 required positional arguments: 'img' and 'content'

2025-02-26 11:09:09,212 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:09:09,231 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:09:09,309 - lightrag - ERROR - Failed to process document doc-87881fb36e9f5389c75454c7761ece0b: extract_entities() missing 2 required positional arguments: 'img' and 'content'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 613, in ainsert
    maybe_new_kg = await extract_entities(
TypeError: extract_entities() missing 2 required positional arguments: 'img' and 'content'

2025-02-26 11:09:09,310 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:09:09,349 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:09:09,411 - lightrag - ERROR - Failed to process document doc-1f8756f59446a38107a8be1aa9b6a8fd: extract_entities() missing 2 required positional arguments: 'img' and 'content'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 613, in ainsert
    maybe_new_kg = await extract_entities(
TypeError: extract_entities() missing 2 required positional arguments: 'img' and 'content'

2025-02-26 11:09:09,412 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:09:09,413 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:09:09,474 - lightrag - ERROR - Failed to process document doc-8015917e642f192276962dc5c82f0035: extract_entities() missing 2 required positional arguments: 'img' and 'content'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 613, in ainsert
    maybe_new_kg = await extract_entities(
TypeError: extract_entities() missing 2 required positional arguments: 'img' and 'content'

2025-02-26 11:09:09,475 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:09:09,476 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:09:09,538 - lightrag - ERROR - Failed to process document doc-f01954951a58e51263cca96d62fefb00: extract_entities() missing 2 required positional arguments: 'img' and 'content'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 613, in ainsert
    maybe_new_kg = await extract_entities(
TypeError: extract_entities() missing 2 required positional arguments: 'img' and 'content'

2025-02-26 11:09:09,539 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:09:09,541 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:09:09,604 - lightrag - ERROR - Failed to process document doc-4b5552c7ac55663b2b002dd63cf226b4: extract_entities() missing 2 required positional arguments: 'img' and 'content'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 613, in ainsert
    maybe_new_kg = await extract_entities(
TypeError: extract_entities() missing 2 required positional arguments: 'img' and 'content'

2025-02-26 11:09:09,606 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:09:09,607 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:09:09,670 - lightrag - ERROR - Failed to process document doc-97d5d4a638969d5050c48d064dcbf3cc: extract_entities() missing 2 required positional arguments: 'img' and 'content'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 613, in ainsert
    maybe_new_kg = await extract_entities(
TypeError: extract_entities() missing 2 required positional arguments: 'img' and 'content'

2025-02-26 11:09:09,672 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:09:09,674 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:09:09,742 - lightrag - ERROR - Failed to process document doc-458c5ff459d71ac15159de1660037e10: extract_entities() missing 2 required positional arguments: 'img' and 'content'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 613, in ainsert
    maybe_new_kg = await extract_entities(
TypeError: extract_entities() missing 2 required positional arguments: 'img' and 'content'

2025-02-26 11:09:09,744 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:09:09,746 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:09:09,807 - lightrag - ERROR - Failed to process document doc-c820138584e3628b850829a18b54dc68: extract_entities() missing 2 required positional arguments: 'img' and 'content'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 613, in ainsert
    maybe_new_kg = await extract_entities(
TypeError: extract_entities() missing 2 required positional arguments: 'img' and 'content'

2025-02-26 11:09:09,809 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:09:09,811 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:09:09,879 - lightrag - ERROR - Failed to process document doc-40a9c7823f84619ed461ccd4f6a33e1b: extract_entities() missing 2 required positional arguments: 'img' and 'content'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 613, in ainsert
    maybe_new_kg = await extract_entities(
TypeError: extract_entities() missing 2 required positional arguments: 'img' and 'content'

2025-02-26 11:09:09,881 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:09:09,883 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:09:09,945 - lightrag - ERROR - Failed to process document doc-f03ca51227f347be6fdcad636c12c88b: extract_entities() missing 2 required positional arguments: 'img' and 'content'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 613, in ainsert
    maybe_new_kg = await extract_entities(
TypeError: extract_entities() missing 2 required positional arguments: 'img' and 'content'

2025-02-26 11:09:09,948 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:09:09,956 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:09:10,017 - lightrag - ERROR - Failed to process document doc-8f1f49d7eec9c94cedbca85b3bd8ad8d: extract_entities() missing 2 required positional arguments: 'img' and 'content'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 613, in ainsert
    maybe_new_kg = await extract_entities(
TypeError: extract_entities() missing 2 required positional arguments: 'img' and 'content'

2025-02-26 11:09:10,020 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:09:10,021 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:09:10,091 - lightrag - ERROR - Failed to process document doc-a4e3ed87c1b2beb7081af8f6bbfb2389: extract_entities() missing 2 required positional arguments: 'img' and 'content'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 613, in ainsert
    maybe_new_kg = await extract_entities(
TypeError: extract_entities() missing 2 required positional arguments: 'img' and 'content'

2025-02-26 11:09:10,094 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:09:10,095 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:09:10,156 - lightrag - ERROR - Failed to process document doc-d12f739158f5b66cda3554b96920d8a4: extract_entities() missing 2 required positional arguments: 'img' and 'content'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 613, in ainsert
    maybe_new_kg = await extract_entities(
TypeError: extract_entities() missing 2 required positional arguments: 'img' and 'content'

2025-02-26 11:09:10,159 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:09:10,161 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:09:10,222 - lightrag - ERROR - Failed to process document doc-f5c5fd1419b86cc720719afc69a5f08e: extract_entities() missing 2 required positional arguments: 'img' and 'content'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 613, in ainsert
    maybe_new_kg = await extract_entities(
TypeError: extract_entities() missing 2 required positional arguments: 'img' and 'content'

2025-02-26 11:09:10,225 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:09:10,231 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:09:10,290 - lightrag - ERROR - Failed to process document doc-e71b8ae320acf14bee521dfdab980576: extract_entities() missing 2 required positional arguments: 'img' and 'content'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 654, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 613, in ainsert
    maybe_new_kg = await extract_entities(
TypeError: extract_entities() missing 2 required positional arguments: 'img' and 'content'

2025-02-26 11:09:10,293 - lightrag - INFO - Writing graph with 0 nodes, 0 edges
2025-02-26 11:14:13,809 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 11:14:13,809 - lightrag - INFO - Load KV llm_response_cache with 0 data
2025-02-26 11:14:13,809 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-26 11:14:13,810 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-26 11:14:13,810 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 0 nodes, 0 edges
2025-02-26 11:14:13,813 - lightrag - INFO - Loaded document status storage with 16 records
2025-02-26 11:14:13,814 - lightrag - INFO - Processing 16 new unique documents
2025-02-26 11:14:14,139 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:14:24,401 - lightrag - INFO - Inserting entities into storage...
2025-02-26 11:14:24,402 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 11:14:24,402 - lightrag - INFO - Inserting 2 vectors to entities
2025-02-26 11:14:24,486 - lightrag - INFO - Inserting 1 vectors to relationships
2025-02-26 11:14:24,563 - lightrag - INFO - Writing graph with 2 nodes, 1 edges
2025-02-26 11:14:24,565 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:14:55,289 - lightrag - INFO - Inserting entities into storage...
2025-02-26 11:14:55,291 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 11:14:55,292 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-26 11:14:55,689 - lightrag - INFO - Inserting 10 vectors to relationships
2025-02-26 11:14:56,005 - lightrag - INFO - Writing graph with 13 nodes, 11 edges
2025-02-26 11:14:56,008 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:15:09,362 - lightrag - INFO - Inserting entities into storage...
2025-02-26 11:15:09,365 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 11:15:09,367 - lightrag - INFO - Inserting 4 vectors to entities
2025-02-26 11:15:09,556 - lightrag - INFO - Inserting 3 vectors to relationships
2025-02-26 11:15:09,687 - lightrag - INFO - Writing graph with 16 nodes, 14 edges
2025-02-26 11:15:09,689 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:15:57,741 - lightrag - INFO - Inserting entities into storage...
2025-02-26 11:15:57,743 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 11:15:57,744 - lightrag - INFO - Inserting 15 vectors to entities
2025-02-26 11:15:58,536 - lightrag - INFO - Inserting 11 vectors to relationships
2025-02-26 11:15:58,938 - lightrag - INFO - Writing graph with 29 nodes, 25 edges
2025-02-26 11:15:58,941 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:16:41,427 - lightrag - INFO - Inserting entities into storage...
2025-02-26 11:16:41,430 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 11:16:41,431 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-26 11:16:42,247 - lightrag - INFO - Inserting 12 vectors to relationships
2025-02-26 11:16:42,794 - lightrag - INFO - Writing graph with 33 nodes, 36 edges
2025-02-26 11:16:42,798 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:17:44,822 - lightrag - INFO - Inserting entities into storage...
2025-02-26 11:17:44,824 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 11:17:44,825 - lightrag - INFO - Inserting 18 vectors to entities
2025-02-26 11:17:46,250 - lightrag - INFO - Inserting 21 vectors to relationships
2025-02-26 11:17:47,199 - lightrag - ERROR - Failed to process document doc-a4e3ed87c1b2beb7081af8f6bbfb2389: CUDA out of memory. Tried to allocate 1.31 GiB. GPU 1 has a total capacity of 23.65 GiB of which 1.17 GiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 20.72 GiB is allocated by PyTorch, and 724.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 656, in ainsert
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 613, in ainsert
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.31 GiB. GPU 1 has a total capacity of 23.65 GiB of which 1.17 GiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 20.72 GiB is allocated by PyTorch, and 724.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 11:17:47,220 - lightrag - INFO - Writing graph with 56 nodes, 56 edges
2025-02-26 11:17:47,229 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:18:21,260 - lightrag - INFO - Inserting entities into storage...
2025-02-26 11:18:21,262 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 11:18:21,263 - lightrag - INFO - Inserting 6 vectors to entities
2025-02-26 11:18:21,801 - lightrag - INFO - Inserting 8 vectors to relationships
2025-02-26 11:18:22,098 - lightrag - INFO - Writing graph with 61 nodes, 64 edges
2025-02-26 11:18:22,103 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:18:46,909 - lightrag - INFO - Inserting entities into storage...
2025-02-26 11:18:46,912 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 11:18:46,914 - lightrag - INFO - Inserting 9 vectors to entities
2025-02-26 11:18:47,796 - lightrag - INFO - Inserting 7 vectors to relationships
2025-02-26 11:18:48,177 - lightrag - INFO - Writing graph with 66 nodes, 70 edges
2025-02-26 11:18:48,203 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:19:15,862 - lightrag - INFO - Inserting entities into storage...
2025-02-26 11:19:15,865 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 11:19:15,866 - lightrag - INFO - Inserting 7 vectors to entities
2025-02-26 11:19:16,665 - lightrag - INFO - Inserting 6 vectors to relationships
2025-02-26 11:19:16,949 - lightrag - INFO - Writing graph with 71 nodes, 75 edges
2025-02-26 11:19:16,954 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:19:41,053 - lightrag - INFO - Inserting entities into storage...
2025-02-26 11:19:41,054 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 11:19:41,055 - lightrag - INFO - Inserting 7 vectors to entities
2025-02-26 11:19:41,929 - lightrag - INFO - Inserting 6 vectors to relationships
2025-02-26 11:19:42,193 - lightrag - INFO - Writing graph with 76 nodes, 80 edges
2025-02-26 11:19:42,235 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:20:00,962 - lightrag - INFO - Inserting entities into storage...
2025-02-26 11:20:00,965 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 11:20:00,966 - lightrag - INFO - Inserting 5 vectors to entities
2025-02-26 11:20:01,648 - lightrag - INFO - Inserting 5 vectors to relationships
2025-02-26 11:20:01,927 - lightrag - INFO - Writing graph with 78 nodes, 83 edges
2025-02-26 11:20:02,099 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:20:24,289 - lightrag - INFO - Inserting entities into storage...
2025-02-26 11:20:24,290 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 11:20:24,291 - lightrag - INFO - Inserting 7 vectors to entities
2025-02-26 11:20:25,324 - lightrag - INFO - Inserting 4 vectors to relationships
2025-02-26 11:20:25,496 - lightrag - INFO - Writing graph with 84 nodes, 87 edges
2025-02-26 11:20:25,501 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:20:45,207 - lightrag - INFO - Inserting entities into storage...
2025-02-26 11:20:45,211 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 11:20:45,213 - lightrag - INFO - Inserting 9 vectors to entities
2025-02-26 11:20:45,582 - lightrag - INFO - Inserting 2 vectors to relationships
2025-02-26 11:20:45,708 - lightrag - INFO - Writing graph with 92 nodes, 89 edges
2025-02-26 11:20:45,714 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:21:05,915 - lightrag - INFO - Inserting entities into storage...
2025-02-26 11:21:05,918 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 11:21:05,918 - lightrag - INFO - Inserting 8 vectors to entities
2025-02-26 11:21:07,146 - lightrag - INFO - Inserting 3 vectors to relationships
2025-02-26 11:21:07,294 - lightrag - INFO - Writing graph with 99 nodes, 92 edges
2025-02-26 11:21:07,300 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:21:45,989 - lightrag - INFO - Inserting entities into storage...
2025-02-26 11:21:45,993 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 11:21:45,994 - lightrag - INFO - Inserting 9 vectors to entities
2025-02-26 11:21:47,617 - lightrag - INFO - Inserting 8 vectors to relationships
2025-02-26 11:21:47,952 - lightrag - INFO - Writing graph with 103 nodes, 100 edges
2025-02-26 11:21:47,960 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:22:09,133 - lightrag - INFO - Inserting entities into storage...
2025-02-26 11:22:09,136 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 11:22:09,137 - lightrag - INFO - Inserting 5 vectors to entities
2025-02-26 11:22:09,342 - lightrag - INFO - Inserting 4 vectors to relationships
2025-02-26 11:22:09,530 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:24:31,761 - lightrag - INFO - Processing 18 new unique documents
2025-02-26 11:24:31,764 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:25:17,848 - lightrag - ERROR - Failed to process document doc-79319c1e90d407042a9759d20ba176ca: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 11:25:17,911 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:25:17,919 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:26:15,009 - lightrag - ERROR - Failed to process document doc-858f41183551479606f76c7a6c4e44b1: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 11:26:15,059 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:26:15,082 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:26:50,997 - lightrag - ERROR - Failed to process document doc-5bf19ad9f79190cbca14d2618635711c: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 11:26:51,049 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:26:51,057 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:27:31,292 - lightrag - ERROR - Failed to process document doc-d7e23f595612c4017bc3860fae580c64: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 11:27:31,357 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:27:31,370 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:28:15,488 - lightrag - ERROR - Failed to process document doc-f866b782a48c04875e852bafeb7a2059: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 11:28:15,539 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:28:15,547 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:29:07,274 - lightrag - ERROR - Failed to process document doc-72730fc3f78af8ddc6a8c10e595704e6: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 11:29:07,330 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:29:07,338 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:29:54,337 - lightrag - ERROR - Failed to process document doc-b03318063ea5502e55d5ce39f1d747e2: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 11:29:54,389 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:29:54,396 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:30:36,114 - lightrag - ERROR - Failed to process document doc-628c99dd00f3b41cf06aa0551fff9c9b: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 11:30:36,166 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:30:36,174 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:31:24,974 - lightrag - ERROR - Failed to process document doc-78d3c37b5ea249fc3760beda62a0723a: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 11:31:25,028 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:31:25,041 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:32:09,676 - lightrag - ERROR - Failed to process document doc-deda6396a83f312df415f1e6705f344e: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 11:32:09,741 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:32:09,749 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:32:50,410 - lightrag - ERROR - Failed to process document doc-1d5dfb80ba668884c0d32675b08cdee5: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 11:32:50,464 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:32:50,478 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:33:37,713 - lightrag - ERROR - Failed to process document doc-84b492efd5bbd5951767d9769ba6b855: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 11:33:37,769 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:33:37,776 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:34:31,385 - lightrag - ERROR - Failed to process document doc-d1cd208df98b91d12df3f88629bdb4f2: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 11:34:31,458 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:34:31,466 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:35:17,785 - lightrag - ERROR - Failed to process document doc-dda836acc0e7c4bf12ca7ee0e4ae68a1: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 11:35:17,841 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:35:17,857 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:36:15,974 - lightrag - ERROR - Failed to process document doc-767d5acc698d1eefe06d7136aba17b85: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 11:36:16,065 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:36:16,078 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:37:05,193 - lightrag - ERROR - Failed to process document doc-95278b0cbc33e3f2ed17b820014d3893: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 11:37:05,251 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:37:05,266 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:37:56,215 - lightrag - ERROR - Failed to process document doc-2afbd7aa765bde7c06493a9a856214f2: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 11:37:56,349 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:37:56,412 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 11:38:29,492 - lightrag - ERROR - Failed to process document doc-13a2015e53578aeb77bdef77bf6a9ef4: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 11:38:29,549 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 11:38:31,501 - lightrag - INFO - kw_prompt result:
2025-02-26 11:38:31,649 - lightrag - INFO - Global query uses 59 entites, 60 relations, 15 text units
2025-02-26 13:37:12,592 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 13:37:12,598 - lightrag - INFO - Load KV llm_response_cache with 2 data
2025-02-26 13:37:12,598 - lightrag - INFO - Load KV full_docs with 15 data
2025-02-26 13:37:12,598 - lightrag - INFO - Load KV text_chunks with 15 data
2025-02-26 13:37:12,602 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 106 nodes, 104 edges
2025-02-26 13:37:12,620 - lightrag - INFO - Loaded document status storage with 34 records
2025-02-26 13:37:44,451 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 13:37:44,456 - lightrag - INFO - Load KV llm_response_cache with 2 data
2025-02-26 13:37:44,457 - lightrag - INFO - Load KV full_docs with 15 data
2025-02-26 13:37:44,457 - lightrag - INFO - Load KV text_chunks with 15 data
2025-02-26 13:37:44,461 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 106 nodes, 104 edges
2025-02-26 13:37:44,475 - lightrag - INFO - Loaded document status storage with 34 records
2025-02-26 13:37:44,476 - lightrag - INFO - Processing 18 new unique documents
2025-02-26 13:37:44,764 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:37:46,092 - lightrag - ERROR - Failed to process document doc-79319c1e90d407042a9759d20ba176ca: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 13:37:46,144 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 13:37:46,153 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:37:46,236 - lightrag - ERROR - Failed to process document doc-858f41183551479606f76c7a6c4e44b1: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 13:37:46,291 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 13:37:46,298 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:37:46,373 - lightrag - ERROR - Failed to process document doc-5bf19ad9f79190cbca14d2618635711c: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 13:37:46,421 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 13:37:46,427 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:37:46,499 - lightrag - ERROR - Failed to process document doc-d7e23f595612c4017bc3860fae580c64: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 13:37:46,548 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 13:37:46,660 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:37:46,761 - lightrag - ERROR - Failed to process document doc-f866b782a48c04875e852bafeb7a2059: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 13:37:46,809 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 13:37:46,816 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:37:46,897 - lightrag - ERROR - Failed to process document doc-72730fc3f78af8ddc6a8c10e595704e6: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 13:37:46,946 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 13:37:46,952 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:37:47,034 - lightrag - ERROR - Failed to process document doc-b03318063ea5502e55d5ce39f1d747e2: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 13:37:47,089 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 13:37:47,100 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:37:47,186 - lightrag - ERROR - Failed to process document doc-628c99dd00f3b41cf06aa0551fff9c9b: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 13:37:47,234 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 13:37:47,240 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:37:47,339 - lightrag - ERROR - Failed to process document doc-78d3c37b5ea249fc3760beda62a0723a: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 13:37:47,388 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 13:37:47,394 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:37:47,493 - lightrag - ERROR - Failed to process document doc-deda6396a83f312df415f1e6705f344e: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 13:37:47,542 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 13:37:47,570 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:37:47,651 - lightrag - ERROR - Failed to process document doc-1d5dfb80ba668884c0d32675b08cdee5: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 13:37:47,703 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 13:37:47,710 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:37:47,791 - lightrag - ERROR - Failed to process document doc-84b492efd5bbd5951767d9769ba6b855: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 13:37:47,841 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 13:37:47,848 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:37:47,929 - lightrag - ERROR - Failed to process document doc-d1cd208df98b91d12df3f88629bdb4f2: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 13:37:47,976 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 13:37:47,985 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:37:48,083 - lightrag - ERROR - Failed to process document doc-dda836acc0e7c4bf12ca7ee0e4ae68a1: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 13:37:48,131 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 13:37:48,189 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:37:48,293 - lightrag - ERROR - Failed to process document doc-767d5acc698d1eefe06d7136aba17b85: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 13:37:48,340 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 13:37:48,346 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:37:48,446 - lightrag - ERROR - Failed to process document doc-95278b0cbc33e3f2ed17b820014d3893: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 13:37:48,494 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 13:37:48,500 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:37:48,574 - lightrag - ERROR - Failed to process document doc-2afbd7aa765bde7c06493a9a856214f2: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 13:37:48,622 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 13:37:48,628 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:37:48,700 - lightrag - ERROR - Failed to process document doc-13a2015e53578aeb77bdef77bf6a9ef4: tuple expected at most 1 argument, got 2
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 494, in extract_entities
    maybe_edges[tuple(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":"{img} contains {k}","keywords":"contains"}])
TypeError: tuple expected at most 1 argument, got 2

2025-02-26 13:37:48,748 - lightrag - INFO - Writing graph with 106 nodes, 104 edges
2025-02-26 13:44:51,987 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 13:44:51,993 - lightrag - INFO - Load KV llm_response_cache with 2 data
2025-02-26 13:44:51,994 - lightrag - INFO - Load KV full_docs with 15 data
2025-02-26 13:44:51,994 - lightrag - INFO - Load KV text_chunks with 15 data
2025-02-26 13:44:51,998 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 106 nodes, 104 edges
2025-02-26 13:44:52,015 - lightrag - INFO - Loaded document status storage with 34 records
2025-02-26 13:44:52,015 - lightrag - INFO - Processing 18 new unique documents
2025-02-26 13:44:52,332 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:44:53,474 - lightrag - INFO - Inserting entities into storage...
2025-02-26 13:44:53,497 - lightrag - ERROR - Failed to process document doc-79319c1e90d407042a9759d20ba176ca: 'source_id'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 510, in extract_entities
    all_entities_data.append(await result)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in _merge_nodes_then_upsert
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in <listcomp>
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
KeyError: 'source_id'

2025-02-26 13:44:53,556 - lightrag - INFO - Writing graph with 118 nodes, 104 edges
2025-02-26 13:44:53,565 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:44:53,648 - lightrag - INFO - Inserting entities into storage...
2025-02-26 13:44:53,669 - lightrag - ERROR - Failed to process document doc-858f41183551479606f76c7a6c4e44b1: 'source_id'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 510, in extract_entities
    all_entities_data.append(await result)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in _merge_nodes_then_upsert
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in <listcomp>
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
KeyError: 'source_id'

2025-02-26 13:44:53,727 - lightrag - INFO - Writing graph with 132 nodes, 104 edges
2025-02-26 13:44:53,734 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:44:53,807 - lightrag - INFO - Inserting entities into storage...
2025-02-26 13:44:53,808 - lightrag - ERROR - Failed to process document doc-5bf19ad9f79190cbca14d2618635711c: 'source_id'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 510, in extract_entities
    all_entities_data.append(await result)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in _merge_nodes_then_upsert
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in <listcomp>
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
KeyError: 'source_id'

2025-02-26 13:44:53,865 - lightrag - INFO - Writing graph with 141 nodes, 104 edges
2025-02-26 13:44:53,872 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:44:53,945 - lightrag - INFO - Inserting entities into storage...
2025-02-26 13:44:53,947 - lightrag - ERROR - Failed to process document doc-d7e23f595612c4017bc3860fae580c64: 'source_id'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 510, in extract_entities
    all_entities_data.append(await result)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in _merge_nodes_then_upsert
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in <listcomp>
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
KeyError: 'source_id'

2025-02-26 13:44:54,005 - lightrag - INFO - Writing graph with 153 nodes, 104 edges
2025-02-26 13:44:54,013 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:44:54,116 - lightrag - INFO - Inserting entities into storage...
2025-02-26 13:44:54,118 - lightrag - ERROR - Failed to process document doc-f866b782a48c04875e852bafeb7a2059: 'source_id'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 510, in extract_entities
    all_entities_data.append(await result)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in _merge_nodes_then_upsert
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in <listcomp>
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
KeyError: 'source_id'

2025-02-26 13:44:54,174 - lightrag - INFO - Writing graph with 167 nodes, 104 edges
2025-02-26 13:44:54,182 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:44:54,263 - lightrag - INFO - Inserting entities into storage...
2025-02-26 13:44:54,265 - lightrag - ERROR - Failed to process document doc-72730fc3f78af8ddc6a8c10e595704e6: 'source_id'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 510, in extract_entities
    all_entities_data.append(await result)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in _merge_nodes_then_upsert
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in <listcomp>
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
KeyError: 'source_id'

2025-02-26 13:44:54,321 - lightrag - INFO - Writing graph with 183 nodes, 104 edges
2025-02-26 13:44:54,438 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:44:54,518 - lightrag - INFO - Inserting entities into storage...
2025-02-26 13:44:54,520 - lightrag - ERROR - Failed to process document doc-b03318063ea5502e55d5ce39f1d747e2: 'source_id'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 510, in extract_entities
    all_entities_data.append(await result)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in _merge_nodes_then_upsert
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in <listcomp>
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
KeyError: 'source_id'

2025-02-26 13:44:54,576 - lightrag - INFO - Writing graph with 198 nodes, 104 edges
2025-02-26 13:44:54,585 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:44:54,671 - lightrag - INFO - Inserting entities into storage...
2025-02-26 13:44:54,673 - lightrag - ERROR - Failed to process document doc-628c99dd00f3b41cf06aa0551fff9c9b: 'source_id'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 510, in extract_entities
    all_entities_data.append(await result)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in _merge_nodes_then_upsert
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in <listcomp>
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
KeyError: 'source_id'

2025-02-26 13:44:54,729 - lightrag - INFO - Writing graph with 211 nodes, 104 edges
2025-02-26 13:44:54,738 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:44:54,838 - lightrag - INFO - Inserting entities into storage...
2025-02-26 13:44:54,841 - lightrag - ERROR - Failed to process document doc-78d3c37b5ea249fc3760beda62a0723a: 'source_id'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 510, in extract_entities
    all_entities_data.append(await result)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in _merge_nodes_then_upsert
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in <listcomp>
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
KeyError: 'source_id'

2025-02-26 13:44:54,895 - lightrag - INFO - Writing graph with 229 nodes, 104 edges
2025-02-26 13:44:54,903 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:44:55,001 - lightrag - INFO - Inserting entities into storage...
2025-02-26 13:44:55,003 - lightrag - ERROR - Failed to process document doc-deda6396a83f312df415f1e6705f344e: 'source_id'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 510, in extract_entities
    all_entities_data.append(await result)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in _merge_nodes_then_upsert
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in <listcomp>
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
KeyError: 'source_id'

2025-02-26 13:44:55,051 - lightrag - INFO - Writing graph with 249 nodes, 104 edges
2025-02-26 13:44:55,059 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:44:55,139 - lightrag - INFO - Inserting entities into storage...
2025-02-26 13:44:55,141 - lightrag - ERROR - Failed to process document doc-1d5dfb80ba668884c0d32675b08cdee5: 'source_id'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 510, in extract_entities
    all_entities_data.append(await result)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in _merge_nodes_then_upsert
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in <listcomp>
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
KeyError: 'source_id'

2025-02-26 13:44:55,189 - lightrag - INFO - Writing graph with 258 nodes, 104 edges
2025-02-26 13:44:55,197 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:44:55,277 - lightrag - INFO - Inserting entities into storage...
2025-02-26 13:44:55,280 - lightrag - ERROR - Failed to process document doc-84b492efd5bbd5951767d9769ba6b855: 'source_id'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 510, in extract_entities
    all_entities_data.append(await result)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in _merge_nodes_then_upsert
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in <listcomp>
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
KeyError: 'source_id'

2025-02-26 13:44:55,330 - lightrag - INFO - Writing graph with 271 nodes, 104 edges
2025-02-26 13:44:55,340 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:44:55,419 - lightrag - INFO - Inserting entities into storage...
2025-02-26 13:44:55,421 - lightrag - ERROR - Failed to process document doc-d1cd208df98b91d12df3f88629bdb4f2: 'source_id'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 510, in extract_entities
    all_entities_data.append(await result)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in _merge_nodes_then_upsert
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in <listcomp>
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
KeyError: 'source_id'

2025-02-26 13:44:55,469 - lightrag - INFO - Writing graph with 290 nodes, 104 edges
2025-02-26 13:44:55,478 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:44:55,576 - lightrag - INFO - Inserting entities into storage...
2025-02-26 13:44:55,578 - lightrag - ERROR - Failed to process document doc-dda836acc0e7c4bf12ca7ee0e4ae68a1: 'source_id'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 510, in extract_entities
    all_entities_data.append(await result)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in _merge_nodes_then_upsert
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in <listcomp>
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
KeyError: 'source_id'

2025-02-26 13:44:55,625 - lightrag - INFO - Writing graph with 302 nodes, 104 edges
2025-02-26 13:44:55,645 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:44:55,747 - lightrag - INFO - Inserting entities into storage...
2025-02-26 13:44:55,750 - lightrag - ERROR - Failed to process document doc-767d5acc698d1eefe06d7136aba17b85: 'source_id'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 510, in extract_entities
    all_entities_data.append(await result)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in _merge_nodes_then_upsert
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in <listcomp>
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
KeyError: 'source_id'

2025-02-26 13:44:55,798 - lightrag - INFO - Writing graph with 310 nodes, 104 edges
2025-02-26 13:44:55,807 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:44:55,906 - lightrag - INFO - Inserting entities into storage...
2025-02-26 13:44:55,908 - lightrag - ERROR - Failed to process document doc-95278b0cbc33e3f2ed17b820014d3893: 'source_id'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 510, in extract_entities
    all_entities_data.append(await result)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in _merge_nodes_then_upsert
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in <listcomp>
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
KeyError: 'source_id'

2025-02-26 13:44:55,956 - lightrag - INFO - Writing graph with 321 nodes, 104 edges
2025-02-26 13:44:55,966 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:44:56,040 - lightrag - INFO - Inserting entities into storage...
2025-02-26 13:44:56,042 - lightrag - ERROR - Failed to process document doc-2afbd7aa765bde7c06493a9a856214f2: 'source_id'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 510, in extract_entities
    all_entities_data.append(await result)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in _merge_nodes_then_upsert
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in <listcomp>
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
KeyError: 'source_id'

2025-02-26 13:44:56,090 - lightrag - INFO - Writing graph with 335 nodes, 104 edges
2025-02-26 13:44:56,101 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 13:44:56,171 - lightrag - INFO - Inserting entities into storage...
2025-02-26 13:44:56,173 - lightrag - ERROR - Failed to process document doc-13a2015e53578aeb77bdef77bf6a9ef4: 'source_id'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 510, in extract_entities
    all_entities_data.append(await result)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in _merge_nodes_then_upsert
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 197, in <listcomp>
    set([dp["source_id"] for dp in nodes_data] + already_source_ids)
KeyError: 'source_id'

2025-02-26 13:44:56,220 - lightrag - INFO - Writing graph with 342 nodes, 104 edges
2025-02-26 14:11:19,613 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 14:11:19,620 - lightrag - INFO - Load KV llm_response_cache with 2 data
2025-02-26 14:11:19,620 - lightrag - INFO - Load KV full_docs with 15 data
2025-02-26 14:11:19,621 - lightrag - INFO - Load KV text_chunks with 15 data
2025-02-26 14:11:19,628 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 342 nodes, 104 edges
2025-02-26 14:11:19,645 - lightrag - INFO - Loaded document status storage with 34 records
2025-02-26 14:11:19,646 - lightrag - INFO - Processing 18 new unique documents
2025-02-26 14:11:19,941 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:11:21,020 - lightrag - INFO - Inserting entities into storage...
2025-02-26 14:11:21,023 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 14:11:21,029 - lightrag - INFO - Inserting 13 vectors to entities
2025-02-26 14:11:22,568 - lightrag - INFO - Inserting 23 vectors to relationships
2025-02-26 14:11:25,641 - lightrag - ERROR - Failed to process document doc-79319c1e90d407042a9759d20ba176ca: CUDA out of memory. Tried to allocate 996.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 107.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.93 GiB memory in use. Of the allocated memory 21.01 GiB is allocated by PyTorch, and 1.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 996.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 107.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.93 GiB memory in use. Of the allocated memory 21.01 GiB is allocated by PyTorch, and 1.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 14:11:25,698 - lightrag - INFO - Writing graph with 343 nodes, 127 edges
2025-02-26 14:11:25,711 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:11:25,819 - lightrag - INFO - Inserting entities into storage...
2025-02-26 14:11:25,822 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 14:11:25,908 - lightrag - INFO - Inserting 17 vectors to entities
2025-02-26 14:11:29,240 - lightrag - ERROR - Failed to process document doc-858f41183551479606f76c7a6c4e44b1: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 1 has a total capacity of 23.65 GiB of which 107.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.93 GiB memory in use. Of the allocated memory 20.33 GiB is allocated by PyTorch, and 2.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 548, in extract_entities
    await entity_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 1 has a total capacity of 23.65 GiB of which 107.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.93 GiB memory in use. Of the allocated memory 20.33 GiB is allocated by PyTorch, and 2.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 14:11:29,324 - lightrag - INFO - Writing graph with 345 nodes, 158 edges
2025-02-26 14:11:29,523 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:11:29,598 - lightrag - INFO - Inserting entities into storage...
2025-02-26 14:11:29,600 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 14:11:29,602 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-26 14:11:31,137 - lightrag - INFO - Inserting 22 vectors to relationships
2025-02-26 14:11:32,784 - lightrag - ERROR - Failed to process document doc-5bf19ad9f79190cbca14d2618635711c: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 1 has a total capacity of 23.65 GiB of which 1.33 GiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 21.71 GiB memory in use. Of the allocated memory 20.17 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 1 has a total capacity of 23.65 GiB of which 1.33 GiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 21.71 GiB memory in use. Of the allocated memory 20.17 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 14:11:32,867 - lightrag - INFO - Writing graph with 346 nodes, 180 edges
2025-02-26 14:11:32,895 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:11:32,975 - lightrag - INFO - Inserting entities into storage...
2025-02-26 14:11:32,977 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 14:11:32,978 - lightrag - INFO - Inserting 14 vectors to entities
2025-02-26 14:11:34,890 - lightrag - INFO - Inserting 24 vectors to relationships
2025-02-26 14:11:36,612 - lightrag - ERROR - Failed to process document doc-d7e23f595612c4017bc3860fae580c64: CUDA out of memory. Tried to allocate 1.50 GiB. GPU 1 has a total capacity of 23.65 GiB of which 339.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.71 GiB memory in use. Of the allocated memory 20.65 GiB is allocated by PyTorch, and 1.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.50 GiB. GPU 1 has a total capacity of 23.65 GiB of which 339.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.71 GiB memory in use. Of the allocated memory 20.65 GiB is allocated by PyTorch, and 1.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 14:11:36,693 - lightrag - INFO - Writing graph with 347 nodes, 204 edges
2025-02-26 14:11:36,758 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:11:36,870 - lightrag - INFO - Inserting entities into storage...
2025-02-26 14:11:36,873 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 14:11:36,885 - lightrag - INFO - Inserting 16 vectors to entities
2025-02-26 14:11:39,255 - lightrag - ERROR - Failed to process document doc-f866b782a48c04875e852bafeb7a2059: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 339.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.71 GiB memory in use. Of the allocated memory 21.15 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 548, in extract_entities
    await entity_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 339.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.71 GiB memory in use. Of the allocated memory 21.15 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 14:11:39,313 - lightrag - INFO - Writing graph with 348 nodes, 233 edges
2025-02-26 14:11:39,326 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:11:39,407 - lightrag - INFO - Inserting entities into storage...
2025-02-26 14:11:39,409 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 14:11:39,411 - lightrag - INFO - Inserting 18 vectors to entities
2025-02-26 14:11:42,219 - lightrag - ERROR - Failed to process document doc-72730fc3f78af8ddc6a8c10e595704e6: CUDA out of memory. Tried to allocate 872.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 339.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.71 GiB memory in use. Of the allocated memory 20.07 GiB is allocated by PyTorch, and 2.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 548, in extract_entities
    await entity_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 872.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 339.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.71 GiB memory in use. Of the allocated memory 20.07 GiB is allocated by PyTorch, and 2.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 14:11:42,275 - lightrag - INFO - Writing graph with 349 nodes, 262 edges
2025-02-26 14:11:42,289 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:11:42,395 - lightrag - INFO - Inserting entities into storage...
2025-02-26 14:11:42,397 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 14:11:42,398 - lightrag - INFO - Inserting 16 vectors to entities
2025-02-26 14:11:43,446 - lightrag - INFO - Inserting 32 vectors to relationships
2025-02-26 14:11:45,608 - lightrag - ERROR - Failed to process document doc-b03318063ea5502e55d5ce39f1d747e2: CUDA out of memory. Tried to allocate 4.00 GiB. GPU 1 has a total capacity of 23.65 GiB of which 3.33 GiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 19.71 GiB memory in use. Of the allocated memory 17.51 GiB is allocated by PyTorch, and 1.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 282, in forward
    k, v = self.to_kv(context).chunk(2, dim = -1)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.00 GiB. GPU 1 has a total capacity of 23.65 GiB of which 3.33 GiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 19.71 GiB memory in use. Of the allocated memory 17.51 GiB is allocated by PyTorch, and 1.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 14:11:45,668 - lightrag - INFO - Writing graph with 350 nodes, 294 edges
2025-02-26 14:11:45,684 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:11:45,766 - lightrag - INFO - Inserting entities into storage...
2025-02-26 14:11:45,768 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 14:11:45,776 - lightrag - INFO - Inserting 15 vectors to entities
2025-02-26 14:11:48,279 - lightrag - ERROR - Failed to process document doc-628c99dd00f3b41cf06aa0551fff9c9b: CUDA out of memory. Tried to allocate 960.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 531.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.52 GiB memory in use. Of the allocated memory 21.18 GiB is allocated by PyTorch, and 916.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 548, in extract_entities
    await entity_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 960.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 531.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.52 GiB memory in use. Of the allocated memory 21.18 GiB is allocated by PyTorch, and 916.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 14:11:48,338 - lightrag - INFO - Writing graph with 351 nodes, 317 edges
2025-02-26 14:11:48,353 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:11:48,477 - lightrag - INFO - Inserting entities into storage...
2025-02-26 14:11:48,479 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 14:11:48,480 - lightrag - INFO - Inserting 19 vectors to entities
2025-02-26 14:11:50,142 - lightrag - INFO - Inserting 27 vectors to relationships
2025-02-26 14:11:52,210 - lightrag - ERROR - Failed to process document doc-78d3c37b5ea249fc3760beda62a0723a: CUDA out of memory. Tried to allocate 642.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 223.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.82 GiB memory in use. Of the allocated memory 20.76 GiB is allocated by PyTorch, and 1.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 642.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 223.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.82 GiB memory in use. Of the allocated memory 20.76 GiB is allocated by PyTorch, and 1.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 14:11:52,286 - lightrag - INFO - Writing graph with 352 nodes, 344 edges
2025-02-26 14:11:52,304 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:11:52,419 - lightrag - INFO - Inserting entities into storage...
2025-02-26 14:11:52,422 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 14:11:52,427 - lightrag - INFO - Inserting 22 vectors to entities
2025-02-26 14:11:56,263 - lightrag - ERROR - Failed to process document doc-deda6396a83f312df415f1e6705f344e: CUDA out of memory. Tried to allocate 2.75 GiB. GPU 1 has a total capacity of 23.65 GiB of which 223.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.82 GiB memory in use. Of the allocated memory 18.63 GiB is allocated by PyTorch, and 3.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 548, in extract_entities
    await entity_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 282, in forward
    k, v = self.to_kv(context).chunk(2, dim = -1)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.75 GiB. GPU 1 has a total capacity of 23.65 GiB of which 223.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.82 GiB memory in use. Of the allocated memory 18.63 GiB is allocated by PyTorch, and 3.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 14:11:56,342 - lightrag - INFO - Writing graph with 353 nodes, 372 edges
2025-02-26 14:11:56,359 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:11:56,444 - lightrag - INFO - Inserting entities into storage...
2025-02-26 14:11:56,446 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 14:11:56,448 - lightrag - INFO - Inserting 13 vectors to entities
2025-02-26 14:11:57,608 - lightrag - INFO - Inserting 22 vectors to relationships
2025-02-26 14:11:59,816 - lightrag - ERROR - Failed to process document doc-1d5dfb80ba668884c0d32675b08cdee5: CUDA out of memory. Tried to allocate 678.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 223.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.82 GiB memory in use. Of the allocated memory 20.17 GiB is allocated by PyTorch, and 2.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 678.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 223.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.82 GiB memory in use. Of the allocated memory 20.17 GiB is allocated by PyTorch, and 2.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 14:11:59,882 - lightrag - INFO - Writing graph with 354 nodes, 393 edges
2025-02-26 14:11:59,899 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:11:59,982 - lightrag - INFO - Inserting entities into storage...
2025-02-26 14:11:59,984 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 14:11:59,986 - lightrag - INFO - Inserting 15 vectors to entities
2025-02-26 14:12:01,546 - lightrag - INFO - Inserting 23 vectors to relationships
2025-02-26 14:12:04,373 - lightrag - ERROR - Failed to process document doc-84b492efd5bbd5951767d9769ba6b855: CUDA out of memory. Tried to allocate 880.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 223.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.82 GiB memory in use. Of the allocated memory 20.75 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 880.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 223.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.82 GiB memory in use. Of the allocated memory 20.75 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 14:12:04,441 - lightrag - INFO - Writing graph with 356 nodes, 416 edges
2025-02-26 14:12:04,459 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:12:04,543 - lightrag - INFO - Inserting entities into storage...
2025-02-26 14:12:04,545 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 14:12:04,547 - lightrag - INFO - Inserting 20 vectors to entities
2025-02-26 14:12:06,049 - lightrag - ERROR - Failed to process document doc-d1cd208df98b91d12df3f88629bdb4f2: CUDA out of memory. Tried to allocate 1.25 GiB. GPU 1 has a total capacity of 23.65 GiB of which 215.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.83 GiB memory in use. Of the allocated memory 21.02 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 548, in extract_entities
    await entity_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.25 GiB. GPU 1 has a total capacity of 23.65 GiB of which 215.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.83 GiB memory in use. Of the allocated memory 21.02 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 14:12:06,117 - lightrag - INFO - Writing graph with 357 nodes, 451 edges
2025-02-26 14:12:06,174 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:12:06,280 - lightrag - INFO - Inserting entities into storage...
2025-02-26 14:12:06,282 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 14:12:06,283 - lightrag - INFO - Inserting 15 vectors to entities
2025-02-26 14:12:07,934 - lightrag - ERROR - Failed to process document doc-dda836acc0e7c4bf12ca7ee0e4ae68a1: CUDA out of memory. Tried to allocate 960.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 215.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.83 GiB memory in use. Of the allocated memory 20.26 GiB is allocated by PyTorch, and 2.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 548, in extract_entities
    await entity_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 960.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 215.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.83 GiB memory in use. Of the allocated memory 20.26 GiB is allocated by PyTorch, and 2.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 14:12:08,003 - lightrag - INFO - Writing graph with 358 nodes, 478 edges
2025-02-26 14:12:08,022 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:12:08,133 - lightrag - INFO - Inserting entities into storage...
2025-02-26 14:12:08,135 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 14:12:08,159 - lightrag - INFO - Inserting 16 vectors to entities
2025-02-26 14:12:10,295 - lightrag - ERROR - Failed to process document doc-767d5acc698d1eefe06d7136aba17b85: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 215.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.83 GiB memory in use. Of the allocated memory 19.96 GiB is allocated by PyTorch, and 2.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 548, in extract_entities
    await entity_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 215.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.83 GiB memory in use. Of the allocated memory 19.96 GiB is allocated by PyTorch, and 2.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 14:12:10,371 - lightrag - INFO - Writing graph with 361 nodes, 507 edges
2025-02-26 14:12:10,390 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:12:10,497 - lightrag - INFO - Inserting entities into storage...
2025-02-26 14:12:10,499 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 14:12:10,501 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-26 14:12:11,656 - lightrag - INFO - Inserting 25 vectors to relationships
2025-02-26 14:12:14,456 - lightrag - ERROR - Failed to process document doc-95278b0cbc33e3f2ed17b820014d3893: CUDA out of memory. Tried to allocate 864.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 215.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.83 GiB memory in use. Of the allocated memory 20.98 GiB is allocated by PyTorch, and 1.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 864.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 215.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.83 GiB memory in use. Of the allocated memory 20.98 GiB is allocated by PyTorch, and 1.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 14:12:14,528 - lightrag - INFO - Writing graph with 362 nodes, 532 edges
2025-02-26 14:12:14,548 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:31:57,011 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 14:31:57,012 - lightrag - INFO - Load KV llm_response_cache with 0 data
2025-02-26 14:31:57,012 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-26 14:31:57,012 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-26 14:31:57,013 - lightrag - INFO - Loaded document status storage with 0 records
2025-02-26 14:31:57,014 - lightrag - INFO - Processing 2 new unique documents
2025-02-26 14:31:57,339 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:32:43,381 - lightrag - INFO - Inserting entities into storage...
2025-02-26 14:32:43,385 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 14:32:43,387 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-26 14:32:44,498 - lightrag - INFO - Inserting 20 vectors to relationships
2025-02-26 14:32:46,139 - lightrag - ERROR - Failed to process document doc-79319c1e90d407042a9759d20ba176ca: CUDA out of memory. Tried to allocate 1.25 GiB. GPU 1 has a total capacity of 23.65 GiB of which 611.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.44 GiB memory in use. Of the allocated memory 21.28 GiB is allocated by PyTorch, and 733.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.25 GiB. GPU 1 has a total capacity of 23.65 GiB of which 611.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.44 GiB memory in use. Of the allocated memory 21.28 GiB is allocated by PyTorch, and 733.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 14:32:46,144 - lightrag - INFO - Writing graph with 12 nodes, 20 edges
2025-02-26 14:32:46,147 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 14:33:32,906 - lightrag - INFO - Inserting entities into storage...
2025-02-26 14:33:32,909 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 14:33:32,913 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-26 14:33:34,523 - lightrag - INFO - Inserting 19 vectors to relationships
2025-02-26 14:33:38,035 - lightrag - ERROR - Failed to process document doc-858f41183551479606f76c7a6c4e44b1: CUDA out of memory. Tried to allocate 1.07 GiB. GPU 1 has a total capacity of 23.65 GiB of which 787.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.27 GiB memory in use. Of the allocated memory 20.69 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.07 GiB. GPU 1 has a total capacity of 23.65 GiB of which 787.12 MiB is free. Process 181889 has 618.00 MiB memory in use. Including non-PyTorch memory, this process has 22.27 GiB memory in use. Of the allocated memory 20.69 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 14:33:38,043 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 15:55:03,297 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 15:55:03,298 - lightrag - INFO - Load KV llm_response_cache with 1 data
2025-02-26 15:55:03,298 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-26 15:55:03,298 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-26 15:55:03,300 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 24 nodes, 39 edges
2025-02-26 15:55:03,303 - lightrag - INFO - Loaded document status storage with 2 records
2025-02-26 15:55:03,303 - lightrag - INFO - Processing 2 new unique documents
2025-02-26 15:55:03,594 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 15:55:04,616 - lightrag - INFO - Inserting entities into storage...
2025-02-26 15:55:04,618 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 15:55:04,620 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-26 15:55:05,692 - lightrag - INFO - Inserting 20 vectors to relationships
2025-02-26 15:55:07,349 - lightrag - ERROR - Failed to process document doc-79319c1e90d407042a9759d20ba176ca: CUDA out of memory. Tried to allocate 1.25 GiB. GPU 2 has a total capacity of 23.65 GiB of which 714.69 MiB is free. Including non-PyTorch memory, this process has 22.95 GiB memory in use. Of the allocated memory 21.28 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.25 GiB. GPU 2 has a total capacity of 23.65 GiB of which 714.69 MiB is free. Including non-PyTorch memory, this process has 22.95 GiB memory in use. Of the allocated memory 21.28 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 15:55:07,362 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 15:55:07,407 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 15:55:07,488 - lightrag - INFO - Inserting entities into storage...
2025-02-26 15:55:07,490 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 15:55:07,493 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-26 15:55:09,065 - lightrag - INFO - Inserting 19 vectors to relationships
2025-02-26 15:55:12,482 - lightrag - ERROR - Failed to process document doc-858f41183551479606f76c7a6c4e44b1: CUDA out of memory. Tried to allocate 1.19 GiB. GPU 2 has a total capacity of 23.65 GiB of which 564.69 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 21.76 GiB is allocated by PyTorch, and 910.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.19 GiB. GPU 2 has a total capacity of 23.65 GiB of which 564.69 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 21.76 GiB is allocated by PyTorch, and 910.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 15:55:12,491 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 15:57:02,908 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 15:57:02,909 - lightrag - INFO - Load KV llm_response_cache with 1 data
2025-02-26 15:57:02,909 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-26 15:57:02,909 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-26 15:57:02,911 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 24 nodes, 39 edges
2025-02-26 15:57:02,915 - lightrag - INFO - Loaded document status storage with 2 records
2025-02-26 15:57:02,916 - lightrag - INFO - Processing 2 new unique documents
2025-02-26 15:57:03,213 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 15:57:04,289 - lightrag - INFO - Inserting entities into storage...
2025-02-26 15:57:04,291 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 15:57:04,293 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-26 15:57:05,371 - lightrag - INFO - Inserting 20 vectors to relationships
2025-02-26 15:57:06,959 - lightrag - ERROR - Failed to process document doc-79319c1e90d407042a9759d20ba176ca: CUDA out of memory. Tried to allocate 506.00 MiB. GPU 2 has a total capacity of 23.65 GiB of which 229.12 MiB is free. Including non-PyTorch memory, this process has 20.70 GiB memory in use. Process 2801969 has 2.72 GiB memory in use. Of the allocated memory 19.53 GiB is allocated by PyTorch, and 733.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 506.00 MiB. GPU 2 has a total capacity of 23.65 GiB of which 229.12 MiB is free. Including non-PyTorch memory, this process has 20.70 GiB memory in use. Process 2801969 has 2.72 GiB memory in use. Of the allocated memory 19.53 GiB is allocated by PyTorch, and 733.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 15:57:06,969 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 15:57:06,974 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 15:57:07,106 - lightrag - INFO - Inserting entities into storage...
2025-02-26 15:57:07,108 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 15:57:07,110 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-26 15:57:08,677 - lightrag - INFO - Inserting 19 vectors to relationships
2025-02-26 15:57:11,996 - lightrag - ERROR - Failed to process document doc-858f41183551479606f76c7a6c4e44b1: CUDA out of memory. Tried to allocate 1.19 GiB. GPU 2 has a total capacity of 23.65 GiB of which 762.69 MiB is free. Including non-PyTorch memory, this process has 22.90 GiB memory in use. Of the allocated memory 21.76 GiB is allocated by PyTorch, and 712.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.19 GiB. GPU 2 has a total capacity of 23.65 GiB of which 762.69 MiB is free. Including non-PyTorch memory, this process has 22.90 GiB memory in use. Of the allocated memory 21.76 GiB is allocated by PyTorch, and 712.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 15:57:12,003 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 17:27:39,420 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 17:27:39,421 - lightrag - INFO - Load KV llm_response_cache with 1 data
2025-02-26 17:27:39,421 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-26 17:27:39,421 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-26 17:27:39,423 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 24 nodes, 39 edges
2025-02-26 17:27:39,427 - lightrag - INFO - Loaded document status storage with 2 records
2025-02-26 17:27:39,428 - lightrag - INFO - Processing 2 new unique documents
2025-02-26 17:27:39,766 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 17:27:40,974 - lightrag - INFO - Inserting entities into storage...
2025-02-26 17:27:40,976 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 17:27:40,979 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-26 17:27:42,100 - lightrag - INFO - Inserting 20 vectors to relationships
2025-02-26 17:27:43,760 - lightrag - ERROR - Failed to process document doc-79319c1e90d407042a9759d20ba176ca: CUDA out of memory. Tried to allocate 1.25 GiB. GPU 1 has a total capacity of 23.65 GiB of which 257.56 MiB is free. Process 181889 has 618.00 MiB memory in use. Process 2959678 has 1.59 GiB memory in use. Including non-PyTorch memory, this process has 21.19 GiB memory in use. Of the allocated memory 20.03 GiB is allocated by PyTorch, and 733.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.25 GiB. GPU 1 has a total capacity of 23.65 GiB of which 257.56 MiB is free. Process 181889 has 618.00 MiB memory in use. Process 2959678 has 1.59 GiB memory in use. Including non-PyTorch memory, this process has 21.19 GiB memory in use. Of the allocated memory 20.03 GiB is allocated by PyTorch, and 733.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 17:27:43,776 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 17:27:43,785 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 17:27:43,899 - lightrag - INFO - Inserting entities into storage...
2025-02-26 17:27:43,900 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 17:27:43,903 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-26 17:27:45,458 - lightrag - ERROR - Failed to process document doc-858f41183551479606f76c7a6c4e44b1: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 257.56 MiB is free. Process 181889 has 618.00 MiB memory in use. Process 2959678 has 1.59 GiB memory in use. Including non-PyTorch memory, this process has 21.19 GiB memory in use. Of the allocated memory 19.59 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 548, in extract_entities
    await entity_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 257.56 MiB is free. Process 181889 has 618.00 MiB memory in use. Process 2959678 has 1.59 GiB memory in use. Including non-PyTorch memory, this process has 21.19 GiB memory in use. Of the allocated memory 19.59 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 17:27:45,495 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 17:28:39,028 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 17:28:39,029 - lightrag - INFO - Load KV llm_response_cache with 1 data
2025-02-26 17:28:39,029 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-26 17:28:39,029 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-26 17:28:39,032 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 24 nodes, 39 edges
2025-02-26 17:28:39,035 - lightrag - INFO - Loaded document status storage with 2 records
2025-02-26 17:28:39,035 - lightrag - INFO - Processing 2 new unique documents
2025-02-26 17:28:39,370 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 17:28:40,655 - lightrag - INFO - Inserting entities into storage...
2025-02-26 17:28:40,658 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 17:28:40,661 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-26 17:28:41,784 - lightrag - INFO - Inserting 20 vectors to relationships
2025-02-26 17:28:43,421 - lightrag - ERROR - Failed to process document doc-79319c1e90d407042a9759d20ba176ca: CUDA out of memory. Tried to allocate 1.25 GiB. GPU 1 has a total capacity of 23.65 GiB of which 257.56 MiB is free. Process 181889 has 618.00 MiB memory in use. Process 2959678 has 1.59 GiB memory in use. Including non-PyTorch memory, this process has 21.19 GiB memory in use. Of the allocated memory 20.03 GiB is allocated by PyTorch, and 733.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.25 GiB. GPU 1 has a total capacity of 23.65 GiB of which 257.56 MiB is free. Process 181889 has 618.00 MiB memory in use. Process 2959678 has 1.59 GiB memory in use. Including non-PyTorch memory, this process has 21.19 GiB memory in use. Of the allocated memory 20.03 GiB is allocated by PyTorch, and 733.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 17:28:43,429 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 17:28:43,433 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 17:28:43,583 - lightrag - INFO - Inserting entities into storage...
2025-02-26 17:28:43,585 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 17:28:43,592 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-26 17:28:45,157 - lightrag - ERROR - Failed to process document doc-858f41183551479606f76c7a6c4e44b1: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 257.56 MiB is free. Process 181889 has 618.00 MiB memory in use. Process 2959678 has 1.59 GiB memory in use. Including non-PyTorch memory, this process has 21.19 GiB memory in use. Of the allocated memory 19.59 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 548, in extract_entities
    await entity_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 1 has a total capacity of 23.65 GiB of which 257.56 MiB is free. Process 181889 has 618.00 MiB memory in use. Process 2959678 has 1.59 GiB memory in use. Including non-PyTorch memory, this process has 21.19 GiB memory in use. Of the allocated memory 19.59 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 17:28:45,165 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 19:02:49,911 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 19:02:49,912 - lightrag - INFO - Load KV llm_response_cache with 1 data
2025-02-26 19:02:49,912 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-26 19:02:49,912 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-26 19:02:49,914 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 24 nodes, 39 edges
2025-02-26 19:02:49,918 - lightrag - INFO - Loaded document status storage with 2 records
2025-02-26 19:02:49,918 - lightrag - INFO - Processing 2 new unique documents
2025-02-26 19:02:50,237 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 19:02:51,395 - lightrag - INFO - Inserting entities into storage...
2025-02-26 19:02:51,397 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 19:02:51,400 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-26 19:02:52,467 - lightrag - INFO - Inserting 20 vectors to relationships
2025-02-26 19:02:54,123 - lightrag - ERROR - Failed to process document doc-79319c1e90d407042a9759d20ba176ca: CUDA out of memory. Tried to allocate 1.25 GiB. GPU 5 has a total capacity of 23.65 GiB of which 712.69 MiB is free. Including non-PyTorch memory, this process has 22.95 GiB memory in use. Of the allocated memory 21.28 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.25 GiB. GPU 5 has a total capacity of 23.65 GiB of which 712.69 MiB is free. Including non-PyTorch memory, this process has 22.95 GiB memory in use. Of the allocated memory 21.28 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 19:02:54,130 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 19:02:54,136 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 19:02:54,241 - lightrag - INFO - Inserting entities into storage...
2025-02-26 19:02:54,243 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 19:02:54,245 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-26 19:02:55,818 - lightrag - INFO - Inserting 19 vectors to relationships
2025-02-26 19:02:59,239 - lightrag - ERROR - Failed to process document doc-858f41183551479606f76c7a6c4e44b1: CUDA out of memory. Tried to allocate 1.19 GiB. GPU 5 has a total capacity of 23.65 GiB of which 562.69 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 21.76 GiB is allocated by PyTorch, and 910.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 565, in extract_entities
    await relationships_vdb.upsert(data_for_vdb)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 120, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 242, in forward
    return self.fn(x, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in forward
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 283, in <lambda>
    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 591, in rearrange
    return reduce(tensor, pattern, reduction="rearrange", **axes_lengths)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 523, in reduce
    return _apply_recipe(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/einops.py", line 250, in _apply_recipe
    tensor = backend.reshape(tensor, final_shapes)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/einops/_backends.py", line 92, in reshape
    return x.reshape(shape)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.19 GiB. GPU 5 has a total capacity of 23.65 GiB of which 562.69 MiB is free. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 21.76 GiB is allocated by PyTorch, and 910.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-02-26 19:02:59,247 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 19:25:00,533 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 19:25:00,533 - lightrag - INFO - Load KV llm_response_cache with 1 data
2025-02-26 19:25:00,534 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-26 19:25:00,534 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-26 19:25:00,536 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 24 nodes, 39 edges
2025-02-26 19:25:00,539 - lightrag - INFO - Loaded document status storage with 2 records
2025-02-26 19:25:00,539 - lightrag - INFO - Processing 2 new unique documents
2025-02-26 19:25:00,821 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 19:25:01,754 - lightrag - ERROR - Failed to process document doc-79319c1e90d407042a9759d20ba176ca: Expected all tensors to be on the same device, but found at least two devices, cuda:5 and cuda:6! (when checking argument for argument weight in method wrapper_CUDA__native_layer_norm)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 122, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 237, in forward
    x = self.norm(x)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 201, in forward
    return F.layer_norm(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/functional.py", line 2546, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:5 and cuda:6! (when checking argument for argument weight in method wrapper_CUDA__native_layer_norm)

2025-02-26 19:25:01,760 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 19:25:01,789 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 19:25:01,866 - lightrag - ERROR - Failed to process document doc-858f41183551479606f76c7a6c4e44b1: Expected all tensors to be on the same device, but found at least two devices, cuda:5 and cuda:6! (when checking argument for argument weight in method wrapper_CUDA__native_layer_norm)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 122, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 312, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 237, in forward
    x = self.norm(x)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 201, in forward
    return F.layer_norm(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/functional.py", line 2546, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:5 and cuda:6! (when checking argument for argument weight in method wrapper_CUDA__native_layer_norm)

2025-02-26 19:25:01,873 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 19:28:08,687 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 19:28:08,687 - lightrag - INFO - Load KV llm_response_cache with 1 data
2025-02-26 19:28:08,688 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-26 19:28:08,688 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-26 19:28:08,690 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 24 nodes, 39 edges
2025-02-26 19:28:08,694 - lightrag - INFO - Loaded document status storage with 2 records
2025-02-26 19:28:08,694 - lightrag - INFO - Processing 2 new unique documents
2025-02-26 19:28:09,026 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 19:28:10,163 - lightrag - ERROR - Failed to process document doc-79319c1e90d407042a9759d20ba176ca: Expected all tensors to be on the same device, but found at least two devices, cuda:5 and cuda:6! (when checking argument for argument weight in method wrapper_CUDA__native_layer_norm)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 122, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 313, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 238, in forward
    x = self.norm(x)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 201, in forward
    return F.layer_norm(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/functional.py", line 2546, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:5 and cuda:6! (when checking argument for argument weight in method wrapper_CUDA__native_layer_norm)

2025-02-26 19:28:10,170 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 19:28:10,205 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 19:28:10,285 - lightrag - ERROR - Failed to process document doc-858f41183551479606f76c7a6c4e44b1: Expected all tensors to be on the same device, but found at least two devices, cuda:5 and cuda:6! (when checking argument for argument weight in method wrapper_CUDA__native_layer_norm)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 122, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 313, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 238, in forward
    x = self.norm(x)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 201, in forward
    return F.layer_norm(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/functional.py", line 2546, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:5 and cuda:6! (when checking argument for argument weight in method wrapper_CUDA__native_layer_norm)

2025-02-26 19:28:10,293 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 19:29:00,955 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 19:29:00,956 - lightrag - INFO - Load KV llm_response_cache with 1 data
2025-02-26 19:29:00,956 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-26 19:29:00,956 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-26 19:29:00,959 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 24 nodes, 39 edges
2025-02-26 19:29:00,962 - lightrag - INFO - Loaded document status storage with 2 records
2025-02-26 19:29:00,962 - lightrag - INFO - Processing 2 new unique documents
2025-02-26 19:29:01,287 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 19:29:02,388 - lightrag - ERROR - Failed to process document doc-79319c1e90d407042a9759d20ba176ca: Expected all tensors to be on the same device, but found at least two devices, cuda:6 and cuda:5!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 122, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 313, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:6 and cuda:5!

2025-02-26 19:29:02,412 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 19:29:02,417 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 19:29:02,500 - lightrag - ERROR - Failed to process document doc-858f41183551479606f76c7a6c4e44b1: Expected all tensors to be on the same device, but found at least two devices, cuda:6 and cuda:5!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 122, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 313, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:6 and cuda:5!

2025-02-26 19:29:02,508 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 19:31:20,747 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 19:31:20,747 - lightrag - INFO - Load KV llm_response_cache with 1 data
2025-02-26 19:31:20,748 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-26 19:31:20,748 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-26 19:31:20,750 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 24 nodes, 39 edges
2025-02-26 19:31:20,753 - lightrag - INFO - Loaded document status storage with 2 records
2025-02-26 19:31:20,754 - lightrag - INFO - Processing 2 new unique documents
2025-02-26 19:31:21,082 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 19:31:22,169 - lightrag - ERROR - Failed to process document doc-79319c1e90d407042a9759d20ba176ca: Expected all tensors to be on the same device, but found at least two devices, cuda:6 and cuda:5!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 122, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 315, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:6 and cuda:5!

2025-02-26 19:31:22,177 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 19:31:22,182 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 19:31:22,261 - lightrag - ERROR - Failed to process document doc-858f41183551479606f76c7a6c4e44b1: Expected all tensors to be on the same device, but found at least two devices, cuda:6 and cuda:5!
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 122, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 315, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:6 and cuda:5!

2025-02-26 19:31:22,280 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 19:38:31,514 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 19:38:31,515 - lightrag - INFO - Load KV llm_response_cache with 1 data
2025-02-26 19:38:31,515 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-26 19:38:31,515 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-26 19:38:31,517 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 24 nodes, 39 edges
2025-02-26 19:38:31,520 - lightrag - INFO - Loaded document status storage with 2 records
2025-02-26 19:38:31,520 - lightrag - INFO - Processing 2 new unique documents
2025-02-26 19:38:31,839 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 19:38:32,710 - lightrag - ERROR - Failed to process document doc-79319c1e90d407042a9759d20ba176ca: Expected all tensors to be on the same device, but found at least two devices, cuda:5 and cuda:6! (when checking argument for argument weight in method wrapper_CUDA__native_layer_norm)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 122, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 314, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 237, in forward
    x = self.norm(x)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 201, in forward
    return F.layer_norm(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/functional.py", line 2546, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:5 and cuda:6! (when checking argument for argument weight in method wrapper_CUDA__native_layer_norm)

2025-02-26 19:38:32,717 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 19:38:32,746 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 19:38:32,822 - lightrag - ERROR - Failed to process document doc-858f41183551479606f76c7a6c4e44b1: Expected all tensors to be on the same device, but found at least two devices, cuda:5 and cuda:6! (when checking argument for argument weight in method wrapper_CUDA__native_layer_norm)
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/retrieval.py", line 122, in encode
    embeddings = model.encode(input_data, is_query=(instruction is not None), instruction=instruction, max_length=max_length)['hidden_states']
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 283, in encode
    return self(**collated_features)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/MM-Embed/a2542c237b5b700ed01b829689756425441cef97/modeling_nvmmembed.py", line 234, in forward
    embeds = self.latent_attention_model(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 314, in forward
    hiddens = cross_attn(hiddens, context = x, mask = None) + hiddens
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v1/2e8b322e2b738a383dae0dde5fa19e0b28a5bb11/modeling_nvembed.py", line 237, in forward
    x = self.norm(x)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 201, in forward
    return F.layer_norm(
  File "/home2/dzdong/anaconda3/envs/mmembed/lib/python3.9/site-packages/torch/nn/functional.py", line 2546, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:5 and cuda:6! (when checking argument for argument weight in method wrapper_CUDA__native_layer_norm)

2025-02-26 19:38:32,828 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 19:44:20,593 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-26 19:44:20,593 - lightrag - INFO - Load KV llm_response_cache with 1 data
2025-02-26 19:44:20,594 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-26 19:44:20,594 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-26 19:44:20,596 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 24 nodes, 39 edges
2025-02-26 19:44:20,599 - lightrag - INFO - Loaded document status storage with 2 records
2025-02-26 19:44:20,599 - lightrag - INFO - Processing 2 new unique documents
2025-02-26 19:44:20,932 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 19:44:22,178 - lightrag - INFO - Inserting entities into storage...
2025-02-26 19:44:22,179 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 19:44:22,182 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-26 19:44:23,249 - lightrag - INFO - Inserting 20 vectors to relationships
2025-02-26 19:44:24,976 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-26 19:44:25,024 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-26 19:44:25,101 - lightrag - INFO - Inserting entities into storage...
2025-02-26 19:44:25,102 - lightrag - INFO - Inserting relationships into storage...
2025-02-26 19:44:25,105 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-26 19:44:26,678 - lightrag - INFO - Inserting 19 vectors to relationships
2025-02-26 19:44:30,229 - lightrag - INFO - Writing graph with 24 nodes, 39 edges
2025-02-27 12:40:41,765 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-27 12:40:41,766 - lightrag - INFO - Load KV llm_response_cache with 1 data
2025-02-27 12:40:41,766 - lightrag - INFO - Load KV full_docs with 2 data
2025-02-27 12:40:41,767 - lightrag - INFO - Load KV text_chunks with 2 data
2025-02-27 12:40:41,770 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 24 nodes, 39 edges
2025-02-27 12:40:41,779 - lightrag - INFO - Loaded document status storage with 2 records
2025-02-27 12:40:43,219 - lightrag - INFO - Truncate 1 to 1 chunks
2025-02-27 14:20:58,251 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-27 14:20:58,252 - lightrag - INFO - Load KV llm_response_cache with 2 data
2025-02-27 14:20:58,253 - lightrag - INFO - Load KV full_docs with 2 data
2025-02-27 14:20:58,253 - lightrag - INFO - Load KV text_chunks with 2 data
2025-02-27 14:20:58,255 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 24 nodes, 39 edges
2025-02-27 14:20:58,262 - lightrag - INFO - Loaded document status storage with 2 records
2025-02-27 14:21:02,339 - lightrag - INFO - kw_prompt result:
2025-02-27 14:21:03,983 - lightrag - INFO - Local query uses 23 entites, 39 relations, 2 text units
2025-02-27 14:23:52,745 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-27 14:23:52,745 - lightrag - INFO - Load KV llm_response_cache with 3 data
2025-02-27 14:23:52,746 - lightrag - INFO - Load KV full_docs with 2 data
2025-02-27 14:23:52,746 - lightrag - INFO - Load KV text_chunks with 2 data
2025-02-27 14:23:52,748 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 24 nodes, 39 edges
2025-02-27 14:23:52,754 - lightrag - INFO - Loaded document status storage with 2 records
2025-02-27 14:23:56,271 - lightrag - INFO - kw_prompt result:
2025-02-27 14:23:57,853 - lightrag - INFO - Global query uses 24 entites, 33 relations, 2 text units
2025-02-27 15:13:58,029 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-27 15:13:58,029 - lightrag - INFO - Load KV llm_response_cache with 0 data
2025-02-27 15:13:58,029 - lightrag - INFO - Load KV full_docs with 0 data
2025-02-27 15:13:58,029 - lightrag - INFO - Load KV text_chunks with 0 data
2025-02-27 15:13:58,030 - lightrag - INFO - Loaded document status storage with 0 records
2025-02-27 15:13:58,030 - lightrag - INFO - Processing 16 new unique documents
2025-02-27 15:13:58,328 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 15:14:32,258 - lightrag - INFO - Inserting entities into storage...
2025-02-27 15:14:32,269 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 15:14:32,270 - lightrag - INFO - Inserting 11 vectors to entities
2025-02-27 15:14:32,585 - lightrag - INFO - Inserting 10 vectors to relationships
2025-02-27 15:14:32,911 - lightrag - INFO - Writing graph with 11 nodes, 10 edges
2025-02-27 15:14:32,924 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 15:15:26,356 - lightrag - INFO - Inserting entities into storage...
2025-02-27 15:15:26,359 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 15:15:26,361 - lightrag - INFO - Inserting 24 vectors to entities
2025-02-27 15:15:27,359 - lightrag - INFO - Inserting 22 vectors to relationships
2025-02-27 15:15:28,271 - lightrag - INFO - Writing graph with 35 nodes, 31 edges
2025-02-27 15:15:28,315 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 15:15:44,789 - lightrag - INFO - Inserting entities into storage...
2025-02-27 15:15:44,790 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 15:15:44,791 - lightrag - INFO - Inserting 5 vectors to entities
2025-02-27 15:15:45,055 - lightrag - INFO - Inserting 5 vectors to relationships
2025-02-27 15:15:45,277 - lightrag - INFO - Writing graph with 39 nodes, 36 edges
2025-02-27 15:15:45,289 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 15:16:13,323 - lightrag - INFO - Inserting entities into storage...
2025-02-27 15:16:13,326 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 15:16:13,328 - lightrag - INFO - Inserting 8 vectors to entities
2025-02-27 15:16:13,919 - lightrag - INFO - Inserting 7 vectors to relationships
2025-02-27 15:16:14,309 - lightrag - INFO - Writing graph with 45 nodes, 42 edges
2025-02-27 15:16:14,314 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 15:16:25,852 - lightrag - INFO - Inserting entities into storage...
2025-02-27 15:16:25,855 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 15:16:25,855 - lightrag - INFO - Inserting 4 vectors to entities
2025-02-27 15:16:26,220 - lightrag - INFO - Inserting 3 vectors to relationships
2025-02-27 15:16:26,368 - lightrag - INFO - Writing graph with 48 nodes, 45 edges
2025-02-27 15:16:26,376 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 15:16:42,370 - lightrag - INFO - Inserting entities into storage...
2025-02-27 15:17:03,953 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 15:17:03,955 - lightrag - INFO - Inserting 7 vectors to entities
2025-02-27 15:17:04,679 - lightrag - INFO - Inserting 3 vectors to relationships
2025-02-27 15:17:04,820 - lightrag - INFO - Writing graph with 54 nodes, 48 edges
2025-02-27 15:17:04,824 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 15:17:29,380 - lightrag - INFO - Inserting entities into storage...
2025-02-27 15:17:29,382 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 15:17:29,383 - lightrag - INFO - Inserting 9 vectors to entities
2025-02-27 15:17:30,401 - lightrag - INFO - Inserting 7 vectors to relationships
2025-02-27 15:17:30,715 - lightrag - INFO - Writing graph with 61 nodes, 54 edges
2025-02-27 15:17:30,735 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 15:17:53,054 - lightrag - INFO - Inserting entities into storage...
2025-02-27 15:18:01,150 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 15:18:01,153 - lightrag - INFO - Inserting 8 vectors to entities
2025-02-27 15:18:02,177 - lightrag - INFO - Inserting 3 vectors to relationships
2025-02-27 15:18:02,414 - lightrag - INFO - Writing graph with 65 nodes, 56 edges
2025-02-27 15:18:02,420 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 15:18:27,049 - lightrag - INFO - Inserting entities into storage...
2025-02-27 15:18:27,053 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 15:18:27,054 - lightrag - INFO - Inserting 5 vectors to entities
2025-02-27 15:18:27,737 - lightrag - INFO - Inserting 7 vectors to relationships
2025-02-27 15:18:28,054 - lightrag - INFO - Writing graph with 69 nodes, 63 edges
2025-02-27 15:18:28,062 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 15:19:01,539 - lightrag - INFO - Inserting entities into storage...
2025-02-27 15:19:01,542 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 15:19:01,543 - lightrag - INFO - Inserting 10 vectors to entities
2025-02-27 15:19:03,070 - lightrag - INFO - Inserting 8 vectors to relationships
2025-02-27 15:19:03,664 - lightrag - INFO - Writing graph with 74 nodes, 70 edges
2025-02-27 15:19:03,673 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 15:19:32,033 - lightrag - INFO - Inserting entities into storage...
2025-02-27 15:19:32,036 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 15:19:32,037 - lightrag - INFO - Inserting 10 vectors to entities
2025-02-27 15:19:33,692 - lightrag - INFO - Inserting 8 vectors to relationships
2025-02-27 15:19:33,993 - lightrag - INFO - Writing graph with 83 nodes, 78 edges
2025-02-27 15:19:34,281 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 15:19:53,269 - lightrag - INFO - Inserting entities into storage...
2025-02-27 15:19:53,271 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 15:19:53,276 - lightrag - INFO - Inserting 5 vectors to entities
2025-02-27 15:19:53,503 - lightrag - INFO - Inserting 5 vectors to relationships
2025-02-27 15:19:53,730 - lightrag - INFO - Writing graph with 86 nodes, 83 edges
2025-02-27 15:19:53,739 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 15:20:04,650 - lightrag - INFO - Inserting entities into storage...
2025-02-27 15:20:04,654 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 15:20:04,655 - lightrag - INFO - Inserting 4 vectors to entities
2025-02-27 15:20:05,379 - lightrag - INFO - Inserting 1 vectors to relationships
2025-02-27 15:20:05,504 - lightrag - INFO - Writing graph with 88 nodes, 83 edges
2025-02-27 15:20:05,522 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 15:20:29,971 - lightrag - INFO - Inserting entities into storage...
2025-02-27 15:20:29,974 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 15:20:29,975 - lightrag - INFO - Inserting 9 vectors to entities
2025-02-27 15:20:31,729 - lightrag - INFO - Inserting 8 vectors to relationships
2025-02-27 15:20:32,096 - lightrag - INFO - Writing graph with 96 nodes, 91 edges
2025-02-27 15:20:32,105 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 15:20:45,228 - lightrag - INFO - Inserting entities into storage...
2025-02-27 15:20:45,232 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 15:20:45,234 - lightrag - INFO - Inserting 3 vectors to entities
2025-02-27 15:20:45,857 - lightrag - INFO - Inserting 3 vectors to relationships
2025-02-27 15:20:46,021 - lightrag - INFO - Writing graph with 100 nodes, 94 edges
2025-02-27 15:20:46,027 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 15:21:07,762 - lightrag - INFO - Inserting entities into storage...
2025-02-27 15:21:07,767 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 15:21:07,768 - lightrag - INFO - Inserting 3 vectors to entities
2025-02-27 15:21:08,440 - lightrag - INFO - Inserting 1 vectors to relationships
2025-02-27 15:21:08,606 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:00:36,856 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-27 16:00:36,859 - lightrag - INFO - Load KV llm_response_cache with 1 data
2025-02-27 16:00:36,859 - lightrag - INFO - Load KV full_docs with 16 data
2025-02-27 16:00:36,859 - lightrag - INFO - Load KV text_chunks with 16 data
2025-02-27 16:00:36,863 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 101 nodes, 95 edges
2025-02-27 16:00:36,883 - lightrag - INFO - Loaded document status storage with 16 records
2025-02-27 16:00:36,884 - lightrag - INFO - All documents have been processed or are duplicates
2025-02-27 16:01:08,732 - lightrag - INFO - Processing 18 new unique documents
2025-02-27 16:01:09,194 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:01:46,251 - lightrag - ERROR - Failed to process document doc-79319c1e90d407042a9759d20ba176ca: unhashable type: 'JpegImageFile'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 493, in extract_entities
    maybe_edges[(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":f"The image {img} contains {k}","keywords":"contains","source_id":compute_mdhash_id(img,prefix="rel-")}])
TypeError: unhashable type: 'JpegImageFile'

2025-02-27 16:01:46,305 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:01:46,312 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:02:12,512 - lightrag - ERROR - Failed to process document doc-858f41183551479606f76c7a6c4e44b1: unhashable type: 'JpegImageFile'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 493, in extract_entities
    maybe_edges[(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":f"The image {img} contains {k}","keywords":"contains","source_id":compute_mdhash_id(img,prefix="rel-")}])
TypeError: unhashable type: 'JpegImageFile'

2025-02-27 16:02:12,572 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:02:12,919 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:02:45,390 - lightrag - ERROR - Failed to process document doc-5bf19ad9f79190cbca14d2618635711c: unhashable type: 'JpegImageFile'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 493, in extract_entities
    maybe_edges[(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":f"The image {img} contains {k}","keywords":"contains","source_id":compute_mdhash_id(img,prefix="rel-")}])
TypeError: unhashable type: 'JpegImageFile'

2025-02-27 16:02:45,443 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:02:45,454 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:03:09,817 - lightrag - ERROR - Failed to process document doc-d7e23f595612c4017bc3860fae580c64: unhashable type: 'JpegImageFile'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 493, in extract_entities
    maybe_edges[(img,k)].extend([{"src_id":img,"tgt_id":k,"weight":5.0,"description":f"The image {img} contains {k}","keywords":"contains","source_id":compute_mdhash_id(img,prefix="rel-")}])
TypeError: unhashable type: 'JpegImageFile'

2025-02-27 16:03:09,871 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:03:09,882 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:45:22,124 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-27 16:45:22,128 - lightrag - INFO - Load KV llm_response_cache with 1 data
2025-02-27 16:45:22,128 - lightrag - INFO - Load KV full_docs with 16 data
2025-02-27 16:45:22,128 - lightrag - INFO - Load KV text_chunks with 16 data
2025-02-27 16:45:22,132 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 101 nodes, 95 edges
2025-02-27 16:45:22,157 - lightrag - INFO - Loaded document status storage with 16 records
2025-02-27 16:45:22,157 - lightrag - INFO - All documents have been processed or are duplicates
2025-02-27 16:45:56,345 - lightrag - INFO - Processing 18 new unique documents
2025-02-27 16:45:56,685 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:45:57,832 - lightrag - ERROR - Failed to process document doc-79319c1e90d407042a9759d20ba176ca: object numpy.ndarray can't be used in 'await' expression
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
TypeError: object numpy.ndarray can't be used in 'await' expression

2025-02-27 16:45:57,880 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:45:57,888 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:45:57,970 - lightrag - ERROR - Failed to process document doc-858f41183551479606f76c7a6c4e44b1: object numpy.ndarray can't be used in 'await' expression
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
TypeError: object numpy.ndarray can't be used in 'await' expression

2025-02-27 16:45:58,034 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:45:58,039 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:45:58,111 - lightrag - ERROR - Failed to process document doc-5bf19ad9f79190cbca14d2618635711c: object numpy.ndarray can't be used in 'await' expression
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
TypeError: object numpy.ndarray can't be used in 'await' expression

2025-02-27 16:45:58,154 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:45:58,160 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:45:58,231 - lightrag - ERROR - Failed to process document doc-d7e23f595612c4017bc3860fae580c64: object numpy.ndarray can't be used in 'await' expression
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
TypeError: object numpy.ndarray can't be used in 'await' expression

2025-02-27 16:45:58,274 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:45:58,280 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:45:58,403 - lightrag - ERROR - Failed to process document doc-f866b782a48c04875e852bafeb7a2059: object numpy.ndarray can't be used in 'await' expression
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
TypeError: object numpy.ndarray can't be used in 'await' expression

2025-02-27 16:45:58,446 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:45:58,452 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:45:58,530 - lightrag - ERROR - Failed to process document doc-72730fc3f78af8ddc6a8c10e595704e6: object numpy.ndarray can't be used in 'await' expression
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
TypeError: object numpy.ndarray can't be used in 'await' expression

2025-02-27 16:45:58,574 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:45:58,580 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:45:58,658 - lightrag - ERROR - Failed to process document doc-b03318063ea5502e55d5ce39f1d747e2: object numpy.ndarray can't be used in 'await' expression
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
TypeError: object numpy.ndarray can't be used in 'await' expression

2025-02-27 16:45:58,702 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:45:58,896 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:45:58,975 - lightrag - ERROR - Failed to process document doc-628c99dd00f3b41cf06aa0551fff9c9b: object numpy.ndarray can't be used in 'await' expression
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
TypeError: object numpy.ndarray can't be used in 'await' expression

2025-02-27 16:45:59,019 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:45:59,025 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:45:59,126 - lightrag - ERROR - Failed to process document doc-78d3c37b5ea249fc3760beda62a0723a: object numpy.ndarray can't be used in 'await' expression
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
TypeError: object numpy.ndarray can't be used in 'await' expression

2025-02-27 16:45:59,170 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:45:59,178 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:45:59,278 - lightrag - ERROR - Failed to process document doc-deda6396a83f312df415f1e6705f344e: object numpy.ndarray can't be used in 'await' expression
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
TypeError: object numpy.ndarray can't be used in 'await' expression

2025-02-27 16:45:59,322 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:45:59,329 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:45:59,409 - lightrag - ERROR - Failed to process document doc-1d5dfb80ba668884c0d32675b08cdee5: object numpy.ndarray can't be used in 'await' expression
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
TypeError: object numpy.ndarray can't be used in 'await' expression

2025-02-27 16:45:59,454 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:45:59,459 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:45:59,538 - lightrag - ERROR - Failed to process document doc-84b492efd5bbd5951767d9769ba6b855: object numpy.ndarray can't be used in 'await' expression
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
TypeError: object numpy.ndarray can't be used in 'await' expression

2025-02-27 16:45:59,583 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:45:59,589 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:45:59,668 - lightrag - ERROR - Failed to process document doc-d1cd208df98b91d12df3f88629bdb4f2: object numpy.ndarray can't be used in 'await' expression
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
TypeError: object numpy.ndarray can't be used in 'await' expression

2025-02-27 16:45:59,712 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:45:59,717 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:45:59,819 - lightrag - ERROR - Failed to process document doc-dda836acc0e7c4bf12ca7ee0e4ae68a1: object numpy.ndarray can't be used in 'await' expression
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
TypeError: object numpy.ndarray can't be used in 'await' expression

2025-02-27 16:45:59,862 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:45:59,868 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:45:59,975 - lightrag - ERROR - Failed to process document doc-767d5acc698d1eefe06d7136aba17b85: object numpy.ndarray can't be used in 'await' expression
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
TypeError: object numpy.ndarray can't be used in 'await' expression

2025-02-27 16:46:00,025 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:46:00,034 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:46:00,154 - lightrag - ERROR - Failed to process document doc-95278b0cbc33e3f2ed17b820014d3893: object numpy.ndarray can't be used in 'await' expression
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 446, in ainsertImage
    await self.chunks_vdb.upsert(chunks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 146, in upsert
    embeddings_list = await asyncio.gather(*embedding_tasks)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/storage.py", line 138, in wrapped_task
    result = await self.embedding_func(batch)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 127, in wait_func
    result = await func(*args, **kwargs)
  File "/home2/dzdong/multimodalGraphRAG/lightrag/utils.py", line 66, in __call__
    return await self.func(*args, **kwargs)
TypeError: object numpy.ndarray can't be used in 'await' expression

2025-02-27 16:46:00,200 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:46:00,206 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:49:05,038 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-27 16:49:05,042 - lightrag - INFO - Load KV llm_response_cache with 1 data
2025-02-27 16:49:05,042 - lightrag - INFO - Load KV full_docs with 16 data
2025-02-27 16:49:05,042 - lightrag - INFO - Load KV text_chunks with 16 data
2025-02-27 16:49:05,046 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 101 nodes, 95 edges
2025-02-27 16:49:05,072 - lightrag - INFO - Loaded document status storage with 33 records
2025-02-27 16:49:05,073 - lightrag - INFO - All documents have been processed or are duplicates
2025-02-27 16:49:56,237 - lightrag - INFO - Processing 18 new unique documents
2025-02-27 16:49:56,572 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:49:57,700 - lightrag - ERROR - Failed to process document doc-79319c1e90d407042a9759d20ba176ca: unhashable type: 'list'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 493, in extract_entities
    maybe_edges[([img],k)].extend([{"src_id":[img],"tgt_id":k,"weight":5.0,"description":f"The image contains {k}","keywords":"contains","source_id":compute_mdhash_id(img,prefix="-")}])
TypeError: unhashable type: 'list'

2025-02-27 16:49:57,745 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:49:57,754 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:49:57,838 - lightrag - ERROR - Failed to process document doc-858f41183551479606f76c7a6c4e44b1: unhashable type: 'list'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 493, in extract_entities
    maybe_edges[([img],k)].extend([{"src_id":[img],"tgt_id":k,"weight":5.0,"description":f"The image contains {k}","keywords":"contains","source_id":compute_mdhash_id(img,prefix="-")}])
TypeError: unhashable type: 'list'

2025-02-27 16:49:57,882 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:49:57,893 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:49:57,965 - lightrag - ERROR - Failed to process document doc-5bf19ad9f79190cbca14d2618635711c: unhashable type: 'list'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 493, in extract_entities
    maybe_edges[([img],k)].extend([{"src_id":[img],"tgt_id":k,"weight":5.0,"description":f"The image contains {k}","keywords":"contains","source_id":compute_mdhash_id(img,prefix="-")}])
TypeError: unhashable type: 'list'

2025-02-27 16:49:58,009 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:49:58,014 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:49:58,087 - lightrag - ERROR - Failed to process document doc-d7e23f595612c4017bc3860fae580c64: unhashable type: 'list'
Traceback (most recent call last):
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 492, in ainsertImage
    raise e
  File "/home2/dzdong/multimodalGraphRAG/lightrag/lightrag.py", line 449, in ainsertImage
    maybe_new_kg = await extract_entities(
  File "/home2/dzdong/multimodalGraphRAG/lightrag/operate.py", line 493, in extract_entities
    maybe_edges[([img],k)].extend([{"src_id":[img],"tgt_id":k,"weight":5.0,"description":f"The image contains {k}","keywords":"contains","source_id":compute_mdhash_id(img,prefix="-")}])
TypeError: unhashable type: 'list'

2025-02-27 16:49:58,131 - lightrag - INFO - Writing graph with 101 nodes, 95 edges
2025-02-27 16:49:58,146 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:56:52,251 - lightrag - INFO - Logger initialized for working directory: ./test
2025-02-27 16:56:52,255 - lightrag - INFO - Load KV llm_response_cache with 1 data
2025-02-27 16:56:52,255 - lightrag - INFO - Load KV full_docs with 16 data
2025-02-27 16:56:52,256 - lightrag - INFO - Load KV text_chunks with 16 data
2025-02-27 16:56:52,259 - lightrag - INFO - Loaded graph from ./test/graph_chunk_entity_relation.graphml with 101 nodes, 95 edges
2025-02-27 16:56:52,279 - lightrag - INFO - Loaded document status storage with 16 records
2025-02-27 16:56:52,280 - lightrag - INFO - Processing 18 new unique documents
2025-02-27 16:56:52,567 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:56:53,577 - lightrag - INFO - Inserting entities into storage...
2025-02-27 16:56:53,580 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 16:56:53,581 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-27 16:56:54,689 - lightrag - INFO - Inserting 19 vectors to relationships
2025-02-27 16:56:55,780 - lightrag - INFO - Writing graph with 112 nodes, 114 edges
2025-02-27 16:56:55,795 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:56:55,872 - lightrag - INFO - Inserting entities into storage...
2025-02-27 16:56:55,874 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 16:56:55,875 - lightrag - INFO - Inserting 14 vectors to entities
2025-02-27 16:56:58,888 - lightrag - INFO - Inserting 17 vectors to relationships
2025-02-27 16:57:00,769 - lightrag - INFO - Writing graph with 125 nodes, 131 edges
2025-02-27 16:57:00,776 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:57:00,848 - lightrag - INFO - Inserting entities into storage...
2025-02-27 16:57:00,849 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 16:57:00,850 - lightrag - INFO - Inserting 11 vectors to entities
2025-02-27 16:57:01,439 - lightrag - INFO - Inserting 17 vectors to relationships
2025-02-27 16:57:02,137 - lightrag - INFO - Writing graph with 135 nodes, 148 edges
2025-02-27 16:57:02,146 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:57:02,218 - lightrag - INFO - Inserting entities into storage...
2025-02-27 16:57:02,220 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 16:57:02,221 - lightrag - INFO - Inserting 13 vectors to entities
2025-02-27 16:57:02,956 - lightrag - INFO - Inserting 15 vectors to relationships
2025-02-27 16:57:03,632 - lightrag - INFO - Writing graph with 147 nodes, 163 edges
2025-02-27 16:57:03,772 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:57:47,681 - lightrag - INFO - Inserting entities into storage...
2025-02-27 16:57:47,684 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 16:57:47,686 - lightrag - INFO - Inserting 21 vectors to entities
2025-02-27 16:57:50,339 - lightrag - INFO - Inserting 32 vectors to relationships
2025-02-27 16:57:53,312 - lightrag - INFO - Writing graph with 166 nodes, 195 edges
2025-02-27 16:57:53,325 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:58:30,238 - lightrag - INFO - Inserting entities into storage...
2025-02-27 16:58:30,241 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 16:58:30,243 - lightrag - INFO - Inserting 16 vectors to entities
2025-02-27 16:58:31,426 - lightrag - INFO - Inserting 28 vectors to relationships
2025-02-27 16:58:32,716 - lightrag - INFO - Writing graph with 181 nodes, 223 edges
2025-02-27 16:58:32,729 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 16:59:16,295 - lightrag - INFO - Inserting entities into storage...
2025-02-27 16:59:16,299 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 16:59:16,302 - lightrag - INFO - Inserting 22 vectors to entities
2025-02-27 16:59:17,672 - lightrag - INFO - Inserting 36 vectors to relationships
2025-02-27 16:59:19,117 - lightrag - INFO - Writing graph with 202 nodes, 259 edges
2025-02-27 16:59:19,134 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 17:00:02,356 - lightrag - INFO - Inserting entities into storage...
2025-02-27 17:00:02,359 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 17:00:02,361 - lightrag - INFO - Inserting 15 vectors to entities
2025-02-27 17:00:04,176 - lightrag - INFO - Inserting 26 vectors to relationships
2025-02-27 17:00:06,416 - lightrag - INFO - Writing graph with 215 nodes, 285 edges
2025-02-27 17:00:06,430 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 17:00:36,719 - lightrag - INFO - Inserting entities into storage...
2025-02-27 17:00:36,722 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 17:00:36,724 - lightrag - INFO - Inserting 20 vectors to entities
2025-02-27 17:00:38,337 - lightrag - INFO - Inserting 24 vectors to relationships
2025-02-27 17:00:39,380 - lightrag - INFO - Writing graph with 235 nodes, 309 edges
2025-02-27 17:00:39,395 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 17:01:12,899 - lightrag - INFO - Inserting entities into storage...
2025-02-27 17:01:12,902 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 17:01:12,904 - lightrag - INFO - Inserting 14 vectors to entities
2025-02-27 17:01:14,326 - lightrag - INFO - Inserting 23 vectors to relationships
2025-02-27 17:01:15,323 - lightrag - INFO - Writing graph with 247 nodes, 332 edges
2025-02-27 17:01:15,337 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 17:02:03,135 - lightrag - INFO - Inserting entities into storage...
2025-02-27 17:02:03,141 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 17:02:03,143 - lightrag - INFO - Inserting 16 vectors to entities
2025-02-27 17:02:04,371 - lightrag - INFO - Inserting 28 vectors to relationships
2025-02-27 17:02:05,827 - lightrag - INFO - Writing graph with 261 nodes, 360 edges
2025-02-27 17:02:05,842 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 17:02:40,099 - lightrag - INFO - Inserting entities into storage...
2025-02-27 17:02:40,101 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 17:02:40,103 - lightrag - INFO - Inserting 14 vectors to entities
2025-02-27 17:02:41,325 - lightrag - INFO - Inserting 24 vectors to relationships
2025-02-27 17:02:42,748 - lightrag - INFO - Writing graph with 274 nodes, 384 edges
2025-02-27 17:02:42,767 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 17:03:30,634 - lightrag - INFO - Inserting entities into storage...
2025-02-27 17:03:30,637 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 17:03:30,639 - lightrag - INFO - Inserting 16 vectors to entities
2025-02-27 17:03:31,865 - lightrag - INFO - Inserting 29 vectors to relationships
2025-02-27 17:03:33,218 - lightrag - INFO - Writing graph with 290 nodes, 413 edges
2025-02-27 17:03:33,237 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 17:04:06,476 - lightrag - INFO - Inserting entities into storage...
2025-02-27 17:04:06,479 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 17:04:06,481 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-27 17:04:07,418 - lightrag - INFO - Inserting 20 vectors to relationships
2025-02-27 17:04:08,234 - lightrag - INFO - Writing graph with 298 nodes, 433 edges
2025-02-27 17:04:08,253 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 17:04:59,256 - lightrag - INFO - Inserting entities into storage...
2025-02-27 17:04:59,259 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 17:04:59,262 - lightrag - INFO - Inserting 20 vectors to entities
2025-02-27 17:05:01,969 - lightrag - INFO - Inserting 32 vectors to relationships
2025-02-27 17:05:04,944 - lightrag - INFO - Writing graph with 307 nodes, 460 edges
2025-02-27 17:05:04,961 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 17:05:35,506 - lightrag - INFO - Inserting entities into storage...
2025-02-27 17:05:35,509 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 17:05:35,510 - lightrag - INFO - Inserting 12 vectors to entities
2025-02-27 17:05:36,652 - lightrag - INFO - Inserting 17 vectors to relationships
2025-02-27 17:05:37,662 - lightrag - INFO - Writing graph with 319 nodes, 477 edges
2025-02-27 17:05:37,683 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 17:06:38,541 - lightrag - INFO - Inserting entities into storage...
2025-02-27 17:06:38,544 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 17:06:38,546 - lightrag - INFO - Inserting 19 vectors to entities
2025-02-27 17:06:39,703 - lightrag - INFO - Inserting 41 vectors to relationships
2025-02-27 17:06:41,292 - lightrag - INFO - Writing graph with 336 nodes, 518 edges
2025-02-27 17:06:41,327 - lightrag - INFO - Inserting 1 vectors to chunks
2025-02-27 17:07:10,122 - lightrag - INFO - Inserting entities into storage...
2025-02-27 17:07:10,124 - lightrag - INFO - Inserting relationships into storage...
2025-02-27 17:07:10,125 - lightrag - INFO - Inserting 8 vectors to entities
2025-02-27 17:07:11,031 - lightrag - INFO - Inserting 13 vectors to relationships
2025-02-27 17:07:11,770 - lightrag - INFO - Writing graph with 342 nodes, 531 edges
2025-02-27 17:07:17,446 - lightrag - INFO - kw_prompt result:
2025-02-27 17:07:17,570 - lightrag - INFO - Local query uses 60 entites, 149 relations, 14 text units
2025-02-27 17:07:17,654 - lightrag - INFO - Global query uses 51 entites, 60 relations, 8 text units
